{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TermP.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxMyvszL7xJq2e4hh9E30o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dntjr41/CV_TermP/blob/main/TermP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision - Term Project [ConvNet Challenge]"
      ],
      "metadata": {
        "id": "_o24CKWzs2Ad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdfBNv1ysja7"
      },
      "outputs": [],
      "source": [
        "# Connect Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "train_file_name = 'colorization_dataset.zip'\n",
        "test_file_name = 'test_dataset.zip'\n",
        "\n",
        "train_zip_path = '/content/drive/MyDrive/colorization_dataset.zip'\n",
        "test_zip_path = '/content/drive/MyDrive/test_dataset.zip'\n",
        "\n",
        "!cp = \"{train_zip_path}\" .\n",
        "!unzip -q '{train_file_name}'\n",
        "!rm '{train_file_name}'\n",
        "\n",
        "!cp = \"{test_zip_path}\" .\n",
        "!unzip -q '{test_file_name}'\n",
        "!rm '{test_file_name}'"
      ],
      "metadata": {
        "id": "O_ARkqd8tGga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Dataset & Color Hint (기존에 올라온 코드 [dataloader])"
      ],
      "metadata": {
        "id": "JHMar44UUyY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(len(os.listdir('./cv_project/train')))\n",
        "print(len(os.listdir('./cv_project/val')))\n",
        "\n",
        "print(len(os.listdir('./test_dataset/hint')))\n",
        "print(len(os.listdir('./test_dataset/mask')))"
      ],
      "metadata": {
        "id": "hD4vcPF1U2aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import os\n",
        "\n",
        "class ColorHintTransform(object):\n",
        "    def __init__(self, size=256, mode=\"train\"):\n",
        "        super(ColorHintTransform, self).__init__()\n",
        "        self.size = size\n",
        "        self.mode = mode\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def bgr_to_lab(self, img):\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        l, ab = lab[:, :, 0], lab[:, :, 1:]\n",
        "        return l, ab\n",
        "\n",
        "    def hint_mask(self, bgr, threshold=[0.95, 0.97, 0.99]):\n",
        "        h, w, c = bgr.shape\n",
        "        mask_threshold = random.choice(threshold)\n",
        "        mask = np.random.random([h, w, 1]) > mask_threshold\n",
        "        return mask\n",
        "\n",
        "    def img_to_mask(self, mask_img):\n",
        "        mask = mask_img[:, :, 0, np.newaxis] >= 255\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, img, mask_img=None):\n",
        "        threshold = [0.95, 0.97, 0.99]\n",
        "        if (self.mode == \"train\") | (self.mode == \"val\"):\n",
        "            image = cv2.resize(img, (self.size, self.size))\n",
        "            mask = self.hint_mask(image, threshold)\n",
        "\n",
        "            hint_image = image * mask\n",
        "\n",
        "            l, ab = self.bgr_to_lab(image)\n",
        "            l_hint, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "            return self.transform(l), self.transform(ab), self.transform(ab_hint)\n",
        "\n",
        "        elif self.mode == \"test\":\n",
        "            image = cv2.resize(img, (self.size, self.size))\n",
        "            hint_image = image * self.img_to_mask(mask_img)\n",
        "\n",
        "            l, _ = self.bgr_to_lab(image)\n",
        "            _, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "            return self.transform(l), self.transform(ab_hint)\n",
        "\n",
        "        else:\n",
        "            return NotImplementedError\n",
        "\n",
        "class ColorHintDataset(data.Dataset):\n",
        "    def __init__(self, root_path, size, mode=\"train\"):\n",
        "        super(ColorHintDataset, self).__init__()\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.size = size\n",
        "        self.mode = mode\n",
        "        self.transforms = ColorHintTransform(self.size, self.mode)\n",
        "        self.examples = None\n",
        "        self.hint = None\n",
        "        self.mask = None\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            train_dir = os.path.join(self.root_path, \"train\")\n",
        "            self.examples = [os.path.join(self.root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "        elif self.mode == \"val\":\n",
        "            val_dir = os.path.join(self.root_path, \"val\")\n",
        "            self.examples = [os.path.join(self.root_path, \"validation\", dirs) for dirs in os.listdir(val_dir)]\n",
        "        elif self.mode == \"test\":\n",
        "            hint_dir = os.path.join(self.root_path, \"hint\")\n",
        "            mask_dir = os.path.join(self.root_path, \"mask\")\n",
        "            self.hint = [os.path.join(self.root_path, \"hint\", dirs) for dirs in os.listdir(hint_dir)]\n",
        "            self.mask = [os.path.join(self.root_path, \"mask\", dirs) for dirs in os.listdir(mask_dir)]\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.mode != \"test\":\n",
        "            return len(self.examples)\n",
        "        else:\n",
        "            return len(self.hint)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == \"test\":\n",
        "            hint_file_name = self.hint[idx]\n",
        "            mask_file_name = self.mask[idx]\n",
        "            hint_img = cv2.imread(hint_file_name)\n",
        "            mask_img = cv2.imread(mask_file_name)\n",
        "\n",
        "            input_l, input_hint = self.transforms(hint_img, mask_img)\n",
        "            sample = {\"l\": input_l, \"hint\": input_hint,\n",
        "                      \"file_name\": \"image_%06d.png\" % int(os.path.basename(hint_file_name).split('.')[0])}\n",
        "        else:\n",
        "            file_name = self.examples[idx]\n",
        "            img = cv2.imread(file_name)\n",
        "            l, ab, hint = self.transforms(img)\n",
        "            sample = {\"l\": l, \"ab\": ab, \"hint\": hint}\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "fTJUtWpHczt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "    if isinstance(input_image, torch.Tensor):\n",
        "        image_tensor = input_image.data\n",
        "    else:\n",
        "        return input_image\n",
        "    image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "    if image_numpy.shape[0] == 1:\n",
        "        image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "    image_numpy = np.clip((np.transpose(image_numpy, (1, 2, 0))), 0, 1) * 255.0\n",
        "    return image_numpy.astype(imtype)\n",
        "\n",
        "\n",
        "# Change to your data root directory\n",
        "root_path = \"./cv_project\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "\n",
        "train_dataset = ColorHintDataset(root_path, 256, \"train\")\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "for i, data in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "    if use_cuda:\n",
        "        l = data[\"l\"].to('cuda')\n",
        "        ab = data[\"ab\"].to('cuda')\n",
        "        hint = data[\"hint\"].to('cuda')\n",
        "    else:\n",
        "        l = data[\"l\"]\n",
        "        ab = data[\"ab\"]\n",
        "        hint = data[\"hint\"]\n",
        "\n",
        "    gt_image = torch.cat((l, ab), dim=1)\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "    gt_np = tensor2im(gt_image)\n",
        "    hint_np = tensor2im(hint_image)\n",
        "\n",
        "    gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2RGB)\n",
        "    hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.imshow(gt_bgr)\n",
        "    plt.figure(2)\n",
        "    plt.imshow(hint_bgr)\n",
        "    plt.show()\n",
        "\n",
        "    input()\n"
      ],
      "metadata": {
        "id": "ayGGPuW8VLoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network Construction (여기부터 구현)"
      ],
      "metadata": {
        "id": "RcCJcxoZdJso"
      }
    }
  ]
}