{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv_project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dntjr41/CV_TermP/blob/main/attention_unet_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 드라이브 마운트"
      ],
      "metadata": {
        "id": "YYIIbLDj2Fo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "4kbz1Cdi2KZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 경로 지정"
      ],
      "metadata": {
        "id": "nRJ5JmPG5uTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/2022_cv_project\n",
        "!pwd\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "rR3n7iOg2Mck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 압축 풀기"
      ],
      "metadata": {
        "id": "McWWPHIk5yHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# # 폴더 복사 하기\n",
        "# import shutil\n",
        "# shutil.copytree('./cv_project', './cv_project_na')\n",
        "\n",
        "# # 파일 크기 확인\n",
        "# filepaths = os.listdir('./cv_project/train')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/val')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/mask')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/hint')\n",
        "# print(len(filepaths))\n",
        "\n",
        "# 압축 풀기\n",
        "file_name = 'cv_project_na'\n",
        "!unzip -qq '{file_name}'\n",
        "\n",
        "# 파일 크기 확인\n",
        "filepaths = os.listdir('./cv_project_na/train')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/val')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/mask')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/hint')\n",
        "print(len(filepaths))"
      ],
      "metadata": {
        "id": "ctcxm9db5wB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab Pro 버전"
      ],
      "metadata": {
        "id": "-PLLd44Q7dBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "ZNoENG5V517u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install pytorch-ssim, mssim (psnr 필요)"
      ],
      "metadata": {
        "id": "mw6ubRU58jcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_ssim\n",
        "!pip install pytorch_msssim"
      ],
      "metadata": {
        "id": "jeY709uN8rFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "TH1XqYwb8vZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from data.dataset import ColorHintDataset\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import cv2\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "# from model.att_unet.att_unet import Unet\n",
        "from model.res_unet.attention_unet import AttentionUNet\n",
        "import matplotlib.image as img\n",
        "import copy, time\n",
        "# from model.sm.model import ResAttdU_Net\n",
        "from utils import AverageMeter, SSIM, psnr, save_img\n",
        "from torchsummary import summary\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project_na\"\n",
        "\n",
        "    check_path = './checkpoints/'\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    # make the directory\n",
        "    os.makedirs('./checkpoints/', exist_ok=True)\n",
        "    os.makedirs('./outputs/', exist_ok=True)\n",
        "    os.makedirs('./outputs/test', exist_ok=True)\n",
        "    os.makedirs('./outputs/GroundTruth', exist_ok=True)\n",
        "    os.makedirs('./outputs/Hint', exist_ok=True)\n",
        "    os.makedirs('./outputs/Output', exist_ok=True)\n",
        "    os.makedirs('./checkpoints', exist_ok=True)\n",
        "\n",
        "    # Load the data\n",
        "    train_dataset = ColorHintDataset(root_path, 256, \"train\")\n",
        "    val_dataset = ColorHintDataset(root_path, 256, \"val\")\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(train_dataset, batch_size=6, num_workers = 2,  shuffle=True)\n",
        "    dataloaders['valid'] = torch.utils.data.DataLoader(val_dataset, batch_size=6, num_workers = 2, shuffle=False)\n",
        "\n",
        "\n",
        "    print('train dataset: ', len(train_dataset))\n",
        "    print('validation dataset: ', len(val_dataset))\n",
        "\n",
        "    # Select the model\n",
        "    models = {'ResUnet': ResUnet(3), 'ResUnetPlusPlus': ResUnetPlusPlus(3), 'UNet': UNet(), 'AttentionUNet' : AttentionUNet()}\n",
        "    # model = ResUnetPlusPlus(3).to(device)\n",
        "    model = AttentionUNet(3).to(device)\n",
        "\n",
        "    # load the model\n",
        "    model.load_state_dict(torch.load('./checkpoints/model-epoch-5-losses-0.01241.pth'))\n",
        "\n",
        "    criterion = torch.nn.L1Loss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    # summary(model, (3, 256, 256))\n",
        "\n",
        "    lmbda = lambda epoch : 0.95\n",
        "    exp_lr_scehduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
        "    epochs = 10\n",
        "\n",
        "    # initialize the\n",
        "    since = time.time()\n",
        "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 999\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            losses = AverageMeter()\n",
        "            psnr_total = 0\n",
        "            ssim_total = 0\n",
        "            count = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for i, data in enumerate(tqdm.tqdm(dataloaders[phase])):\n",
        "                if use_cuda:\n",
        "                    l = data[\"l\"].to(device)\n",
        "                    ab = data[\"ab\"].to(device)\n",
        "                    hint = data[\"hint\"].to(device)\n",
        "                else:\n",
        "                    l = data[\"l\"]\n",
        "                    ab = data[\"ab\"]\n",
        "                    hint = data[\"hint\"]\n",
        "\n",
        "                gt_image = torch.cat((l, ab), dim=1)\n",
        "                hint_image = torch.cat((l, hint), dim=1)\n",
        "                hint_image = hint_image.float().to(device)\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(hint_image)\n",
        "                    loss = criterion(outputs, ab)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        # zero the parameter gradients\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                losses.update(loss.item(), hint_image.size(0))\n",
        "\n",
        "\n",
        "                if phase == 'train':\n",
        "                  if i % 500 == 0:\n",
        "                    print('\\t Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(loss=losses))\n",
        "                \n",
        "                else:\n",
        "                  outputs = torch.cat((l, outputs), dim = 1)\n",
        "                  out_hint_np = tensor2im(outputs)\n",
        "                  out_hint_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "                  hint_np = tensor2im(hint_image)\n",
        "                  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "                  gt_np = tensor2im(gt_image)\n",
        "                  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "                  # psnr, ssim = save_img(gt_bgr, hint_bgr, out_hint_bgr, i)\n",
        "                  # psnr_total += psnr\n",
        "                  # ssim_total += ssim\n",
        "\n",
        "            if phase == 'train':\n",
        "                exp_lr_scehduler.step()\n",
        "                train_loss.append(losses.avg)\n",
        "\n",
        "            else:\n",
        "                # print(' {} PSNR AVG : {:.4f} SSIM AVG : {:.4f}'.format(phase, psnr_total/len(dataloaders[phase]), ssim_total/len(dataloaders[phase])))\n",
        "                valid_loss.append(losses.avg)\n",
        "\n",
        "            print(' {} Loss: {:.3f} '.format(phase, losses.avg))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and losses.avg < best_loss:\n",
        "                best_idx = epoch\n",
        "                best_loss = losses.avg\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "                # Save model & checkpoint\n",
        "                torch.save(model.state_dict(), './checkpoints/model-epoch-{}-losses-{:.5f}.pth'.format(epoch + 1, best_loss))\n",
        "\n",
        "                print('==> best model saved - %d / %.3f' % (best_idx, best_loss))\n",
        "\n",
        "    # Training Result\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.4f' % (best_idx, best_loss))\n",
        "\n",
        "\n",
        "    # Plot the training procedure\n",
        "    epoch_axis = np.arange(0, epochs)\n",
        "    plt.figure()\n",
        "    plt.title('LOSS')\n",
        "    plt.plot(epoch_axis, train_loss, epoch_axis, valid_loss, 'r-')\n",
        "    plt.legend(['Train', 'Validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "yukf3GiG8sD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test & Predict"
      ],
      "metadata": {
        "id": "0tN_3Gf_8z5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data.dataset import ColorHintDataset\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import os\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "from model.res_unet.attention_unet import AttentionUNet\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "  \n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project_na\"\n",
        "\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    test_dataset = ColorHintDataset(root_path, 256, 'test')\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['test'] = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle=False)\n",
        "    print('test dataset: ', len(test_dataset))\n",
        "\n",
        "\n",
        "    # state_dict = torch.load(check_point)\n",
        "    model = AttentionUNet(3).to(device)\n",
        "    model.load_state_dict(torch.load('./checkpoints/model-epoch-5-losses-0.01241.pth'))\n",
        "\n",
        "    os.makedirs('outputs/test', exist_ok=True)\n",
        "\n",
        "    model.eval()\n",
        "    for i, data in enumerate(tqdm.tqdm(dataloaders['test'])):\n",
        "        if use_cuda:\n",
        "            l = data[\"l\"].to(device)\n",
        "            hint = data[\"hint\"].to(device)\n",
        "            file_name = data[\"file_name\"][0]\n",
        "\n",
        "        hint_image = torch.cat((l, hint), dim=1)\n",
        "        hint_np = tensor2im(hint_image)\n",
        "        hint_image = hint_image.float().to(device)\n",
        "\n",
        "        output = model(hint_image).squeeze(1)\n",
        "        output = torch.cat((l, output), dim = 1)\n",
        "        out_hint_np = tensor2im(output)\n",
        "\n",
        "        hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "        out_hint_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "\n",
        "        plt.figure(1)\n",
        "        cv2_imshow(hint_bgr)\n",
        "        plt.figure(2)\n",
        "        cv2_imshow(out_hint_bgr)\n",
        "\n",
        "        input()\n",
        "        \n",
        "        # 사진 저장\n",
        "        fname = str(file_name).replace(\"['\", '')\n",
        "        fname = fname.replace(\"']\", '')\n",
        "\n",
        "        cv2.imwrite(\"outputs/test/\"+fname, out_hint_bgr)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "rJX86dkc82Eo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}