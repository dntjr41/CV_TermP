{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Colorization_UNet.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dntjr41/CV_TermP/blob/main/Image_Colorization_UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision - Term Project [ConvNet Challenge]"
      ],
      "metadata": {
        "id": "_o24CKWzs2Ad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdfBNv1ysja7"
      },
      "outputs": [],
      "source": [
        "# Connect Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TaqmI1B_zh87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "train_file_name = 'colorization_dataset.zip'\n",
        "test_file_name = 'test_dataset.zip'\n",
        "\n",
        "train_zip_path = '/content/drive/MyDrive/colorization_dataset.zip'\n",
        "test_zip_path = '/content/drive/MyDrive/test_dataset.zip'\n",
        "\n",
        "!cp = \"{train_zip_path}\" .\n",
        "!unzip -q '{train_file_name}'\n",
        "!rm '{train_file_name}'\n",
        "\n",
        "!cp = \"{test_zip_path}\" .\n",
        "!unzip -q '{test_file_name}'\n",
        "!rm '{test_file_name}'"
      ],
      "metadata": {
        "id": "O_ARkqd8tGga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Dataset & Color Hint (기존에 올라온 코드 [dataloader])"
      ],
      "metadata": {
        "id": "JHMar44UUyY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(len(os.listdir('./cv_project/train')))\n",
        "print(len(os.listdir('./cv_project/val')))\n",
        "\n",
        "print(len(os.listdir('./test_dataset/hint')))\n",
        "print(len(os.listdir('./test_dataset/mask')))"
      ],
      "metadata": {
        "id": "hD4vcPF1U2aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class ColorHintTransform(object):\n",
        "  def __init__(self, size=256, mode=\"train\"):\n",
        "    super(ColorHintTransform, self).__init__()\n",
        "    self.size = size\n",
        "    self.mode = mode\n",
        "    self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  def bgr_to_lab(self, img):\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, ab = lab[:, :, 0], lab[:, :, 1:]\n",
        "    return l, ab\n",
        "\n",
        "  def hint_mask(self, bgr, threshold=[0.95, 0.97, 0.99]):\n",
        "    h, w, c = bgr.shape\n",
        "    mask_threshold = random.choice(threshold)\n",
        "    mask = np.random.random([h, w, 1]) > mask_threshold\n",
        "    return mask\n",
        "\n",
        "  def img_to_mask(self, mask_img):\n",
        "    mask = mask_img[:, :, 0, np.newaxis] >= 255\n",
        "    return mask\n",
        "\n",
        "  def __call__(self, img, mask_img=None):\n",
        "    threshold = [0.95, 0.97, 0.99]\n",
        "    if (self.mode == \"train\") | (self.mode == \"val\"):\n",
        "      image = cv2.resize(img, (self.size, self.size))\n",
        "      mask = self.hint_mask(image, threshold)\n",
        "\n",
        "      hint_image = image * mask\n",
        "\n",
        "      l, ab = self.bgr_to_lab(image)\n",
        "      l_hint, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "      return self.transform(l), self.transform(ab), self.transform(ab_hint)\n",
        "\n",
        "    elif self.mode == \"test\":\n",
        "      image = cv2.resize(img, (self.size, self.size))\n",
        "      hint_image = image * self.img_to_mask(mask_img)\n",
        "\n",
        "      l, _ = self.bgr_to_lab(image)\n",
        "      _, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "      return self.transform(l), self.transform(ab_hint)\n",
        "\n",
        "    else:\n",
        "      return NotImplementedError\n",
        "\n",
        "\n",
        "class ColorHintDataset(data.Dataset):\n",
        "  def __init__(self, root_path, size):\n",
        "    super(ColorHintDataset, self).__init__()\n",
        "\n",
        "    self.root_path = root_path\n",
        "    self.size = size\n",
        "    self.transforms = None\n",
        "    self.examples = None\n",
        "    self.hint = None\n",
        "    self.mask = None\n",
        "\n",
        "  def set_mode(self, mode):\n",
        "    self.mode = mode\n",
        "    self.transforms = ColorHintTransform(self.size, mode)\n",
        "    if mode == \"train\":\n",
        "      train_dir = os.path.join(self.root_path, \"train\")\n",
        "      self.examples = [os.path.join(self.root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "    elif mode == \"val\":\n",
        "      val_dir = os.path.join(self.root_path, \"val\")\n",
        "      self.examples = [os.path.join(self.root_path, \"val\", dirs) for dirs in os.listdir(val_dir)]\n",
        "    elif mode == \"test\":\n",
        "      hint_dir = os.path.join(self.root_path, \"hint\")\n",
        "      mask_dir = os.path.join(self.root_path, \"mask\")\n",
        "      self.hint = [os.path.join(self.root_path, \"hint\", dirs) for dirs in os.listdir(hint_dir)]\n",
        "      self.mask = [os.path.join(self.root_path, \"mask\", dirs) for dirs in os.listdir(mask_dir)]\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "\n",
        "  def __len__(self):\n",
        "    if self.mode != \"test\":\n",
        "      return len(self.examples)\n",
        "    else:\n",
        "      return len(self.hint)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.mode == \"test\":\n",
        "      hint_file_name = self.hint[idx]\n",
        "      mask_file_name = self.mask[idx]\n",
        "      hint_img = cv2.imread(hint_file_name)\n",
        "      mask_img = cv2.imread(mask_file_name)\n",
        "\n",
        "      input_l, input_hint = self.transforms(hint_img, mask_img)\n",
        "      sample = {\"l\": input_l, \"hint\": input_hint,\n",
        "                \"file_name\": \"image_%06d.png\" % int(os.path.basename(hint_file_name).split('.')[0])}\n",
        "    else:\n",
        "      file_name = self.examples[idx]\n",
        "      img = cv2.imread(file_name)\n",
        "      l, ab, hint = self.transforms(img)\n",
        "      sample = {\"l\": l, \"ab\": ab, \"hint\": hint}\n",
        "\n",
        "    return sample\n",
        "\n",
        "\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "    if isinstance(input_image, torch.Tensor):\n",
        "        image_tensor = input_image.data\n",
        "    else:\n",
        "        return input_image\n",
        "    image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "    if image_numpy.shape[0] == 1:\n",
        "        image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "    image_numpy = np.clip((np.transpose(image_numpy, (1, 2, 0))), 0, 1) * 255.0\n",
        "    return image_numpy.astype(imtype)\n",
        "\n"
      ],
      "metadata": {
        "id": "fTJUtWpHczt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.utils.data as data\n",
        "# import cv2\n",
        "# import tqdm\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.image as img\n",
        "\n",
        "# # Change to your data root directory\n",
        "# root_path = \"./test_dataset\"\n",
        "# # Depend on runtime setting\n",
        "# use_cuda = True\n",
        "\n",
        "# train_dataset = ColorHintDataset(root_path, 256, \"test\")\n",
        "# train_dataloader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# for i, data in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "#     if use_cuda:\n",
        "#         l = data[\"l\"].to('cuda')\n",
        "#         ab = data[\"ab\"].to('cuda')\n",
        "#         hint = data[\"hint\"].to('cuda')\n",
        "#     else:\n",
        "#         l = data[\"l\"]\n",
        "#         ab = data[\"ab\"]\n",
        "#         hint = data[\"hint\"]\n",
        "\n",
        "#     gt_image = torch.cat((l, ab), dim=1)\n",
        "#     hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "#     gt_np = tensor2im(gt_image)\n",
        "#     hint_np = tensor2im(hint_image)\n",
        "\n",
        "#     gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2RGB)\n",
        "#     hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "#     plt.figure(1)\n",
        "#     plt.imshow(hint_bgr)\n",
        "#     plt.show()\n",
        "\n",
        "#     input()"
      ],
      "metadata": {
        "id": "ayGGPuW8VLoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network Construction (여기부터 구현)"
      ],
      "metadata": {
        "id": "RcCJcxoZdJso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet"
      ],
      "metadata": {
        "id": "s_ddxhsp4hwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(nn.Conv2d(nin, nout, 3, padding=1, stride=1),\n",
        "                                         nn.BatchNorm2d(nout),\n",
        "                                         nn.ReLU(inplace=True),\n",
        "                                         nn.Conv2d(nout, nout, 3, padding=1, stride=1),\n",
        "                                         nn.BatchNorm2d(nout),\n",
        "                                         nn.ReLU(inplace=True)\n",
        "                                         )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super().__init__()\n",
        "        self.down_conv = nn.Sequential(nn.MaxPool2d(2),\n",
        "                                       DoubleConv(nin, nout))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super().__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.double_conv = DoubleConv(nin, nout)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # padding\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2))\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.double_conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(nin, nout, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super().__init__()\n",
        "        self.in_conv = DoubleConv(nin, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024 // 2)\n",
        "        self.up1 = Up(1024, 512 // 2)\n",
        "        self.up2 = Up(512, 256 // 2)\n",
        "        self.up3 = Up(256, 128 // 2)\n",
        "        self.up4 = Up(128, 64)\n",
        "        self.out_conv = OutConv(64, nout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.in_conv(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.out_conv(x)\n",
        "        return x\n",
        "# from torch import nn\n",
        "\n",
        "# class conv_block(nn.Module):\n",
        "#     def __init__(self,ch_in,ch_out):\n",
        "#         super(conv_block,self).__init__()\n",
        "#         self.conv = nn.Sequential(\n",
        "#             nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
        "#             nn.BatchNorm2d(ch_out),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
        "#             nn.BatchNorm2d(ch_out),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "\n",
        "\n",
        "#     def forward(self,x):\n",
        "#         x = self.conv(x)\n",
        "#         return x\n",
        "\n",
        "# class up_conv(nn.Module):\n",
        "#     def __init__(self,ch_in,ch_out):\n",
        "#         super(up_conv,self).__init__()\n",
        "#         self.up = nn.Sequential(\n",
        "#             nn.Upsample(scale_factor=2),\n",
        "#             nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
        "# \t\t    nn.BatchNorm2d(ch_out),\n",
        "# \t\t\tnn.ReLU(inplace=True)\n",
        "#         )\n",
        "\n",
        "#     def forward(self,x):\n",
        "#         x = self.up(x)\n",
        "#         return x\n",
        "\n",
        "# class U_Net(nn.Module):\n",
        "#     def __init__(self,img_ch=3,output_ch=3):\n",
        "#         super(U_Net,self).__init__()\n",
        "        \n",
        "#         self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "#         self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n",
        "#         self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
        "#         self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
        "#         self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
        "#         self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
        "\n",
        "#         self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
        "#         self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
        "\n",
        "#         self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
        "#         self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
        "        \n",
        "#         self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
        "#         self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
        "        \n",
        "#         self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
        "#         self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
        "\n",
        "#         self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "\n",
        "#     def forward(self,x):\n",
        "#         # encoding path\n",
        "#         x1 = self.Conv1(x)\n",
        "\n",
        "#         x2 = self.Maxpool(x1)\n",
        "#         x2 = self.Conv2(x2)\n",
        "        \n",
        "#         x3 = self.Maxpool(x2)\n",
        "#         x3 = self.Conv3(x3)\n",
        "\n",
        "#         x4 = self.Maxpool(x3)\n",
        "#         x4 = self.Conv4(x4)\n",
        "\n",
        "#         x5 = self.Maxpool(x4)\n",
        "#         x5 = self.Conv5(x5)\n",
        "\n",
        "#         # decoding + concat path\n",
        "#         d5 = self.Up5(x5)\n",
        "#         d5 = torch.cat((x4,d5),dim=1)\n",
        "        \n",
        "#         d5 = self.Up_conv5(d5)\n",
        "        \n",
        "#         d4 = self.Up4(d5)\n",
        "#         d4 = torch.cat((x3,d4),dim=1)\n",
        "#         d4 = self.Up_conv4(d4)\n",
        "\n",
        "#         d3 = self.Up3(d4)\n",
        "#         d3 = torch.cat((x2,d3),dim=1)\n",
        "#         d3 = self.Up_conv3(d3)\n",
        "\n",
        "#         d2 = self.Up2(d3)\n",
        "#         d2 = torch.cat((x1,d2),dim=1)\n",
        "#         d2 = self.Up_conv2(d2)\n",
        "\n",
        "#         d1 = self.Conv_1x1(d2)\n",
        "\n",
        "#         return d1\n"
      ],
      "metadata": {
        "id": "wTrr02I_4kdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "1ky36MZd5nP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_ssim\n",
        "!pip install pytorch_msssim"
      ],
      "metadata": {
        "id": "u5n_yJICYUgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from skimage.metrics import structural_similarity\n",
        "from pytorch_msssim import ssim\n",
        "import pytorch_ssim\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "## calculate loss per image##\n",
        "class AverageMeter(object):\n",
        "  '''A handy class from the PyTorch ImageNet tutorial'''\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "  def reset(self):\n",
        "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val * n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count\n",
        "\n",
        "#SSIM##\n",
        "def SSIM(img_A, img_B):\n",
        "    img1 = ToTensor()(img_A).unsqueeze(0)\n",
        "    img2 = ToTensor()(img_B).unsqueeze(0)\n",
        "    if torch.cuda.is_available():\n",
        "        img1 = img1.cuda()\n",
        "        img2 = img2.cuda()\n",
        "    ssim_val = round(ssim(img1, img2).item(),2)\n",
        "    return ssim_val\n",
        "\n",
        "def psnr(img_A, img_B):\n",
        "    score = cv2.PSNR(img_A, img_B)\n",
        "    return score\n",
        "\n",
        "##SAVE IMG##\n",
        "def save_img(gt, hint, output, num):\n",
        "    SSIM_VAL = SSIM(gt, output)\n",
        "    PSNR = psnr(gt, output)\n",
        "    cv2.imwrite(\"outputs/GroundTruth/\"+str(num)+\"gt.png\", gt)\n",
        "    cv2.imwrite(\"outputs/Hint/\"+str(num)+\"hint.png\", hint)\n",
        "    cv2.imwrite(\"outputs/Output/\"+str(num)+\"_ssim:\"+str(SSIM_VAL)+\"_psnr:\"+str(PSNR)+\".png\", output)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FlxooYAT5owr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, Validation, Test Fuction"
      ],
      "metadata": {
        "id": "nR9YMEcz9WVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "##TRAIN##\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    print('Starting training epoch {}'.format(epoch))\n",
        "    model.train()\n",
        "    use_cuda = True\n",
        "    # Prepare value counters and timers\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    for i, data in enumerate(tqdm.tqdm(train_loader)):\n",
        "        if use_cuda:\n",
        "            l = data[\"l\"].to('cuda')\n",
        "            ab = data[\"ab\"].to('cuda')\n",
        "            hint = data[\"hint\"].to('cuda')\n",
        "        else:\n",
        "            l = data[\"l\"]\n",
        "            ab = data[\"ab\"]\n",
        "            hint = data[\"hint\"]\n",
        "        gt_image = torch.cat((l, ab), dim=1)\n",
        "        hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "        # Run forward pass\n",
        "        output_hint = model(hint_image)\n",
        "        loss = criterion(output_hint, gt_image)\n",
        "        losses.update(loss.item(), hint_image.size(0))\n",
        "        # Compute gradient and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print model accuracy -- in the code below, val refers to value, not validation\n",
        "        if i % 100 == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(epoch, i, len(train_loader), loss=losses))\n",
        "\n",
        "    print('Finished training epoch {}'.format(epoch))\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, save_images, epoch):\n",
        "    model.eval()\n",
        "    use_cuda = True\n",
        "    # Prepare value counters and timers\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    shutil.rmtree(\"outputs/Output\")\n",
        "    os.makedirs('outputs/Output', exist_ok=True)\n",
        "\n",
        "    for i, data in enumerate(tqdm.tqdm(val_loader)):\n",
        "        if use_cuda:\n",
        "            l = data[\"l\"].to('cuda')\n",
        "            ab = data[\"ab\"].to('cuda')\n",
        "            hint = data[\"hint\"].to('cuda')\n",
        "        else:\n",
        "            l = data[\"l\"]\n",
        "            ab = data[\"ab\"]\n",
        "            hint = data[\"hint\"]\n",
        "        gt_image = torch.cat((l, ab), dim=1)\n",
        "        hint_image = torch.cat((l, hint), dim=1)\n",
        "        output_hint = model(hint_image)\n",
        "\n",
        "        loss = criterion(output_hint, gt_image)\n",
        "        losses.update(loss.item(), hint_image.size(0))\n",
        "\n",
        "        # Print model accuracy -- in the code below, val refers to both value and validation\n",
        "        if i % 100 == 0:\n",
        "            print('Validate: [{0}/{1}]\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(i, len(val_loader), loss=losses))\n",
        "        out_hint_np = tensor2im(output_hint)\n",
        "        out_hint_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        hint_np = tensor2im(hint_image)\n",
        "        hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        gt_np = tensor2im(gt_image)\n",
        "        gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        save_img(gt_bgr, hint_bgr, out_hint_bgr, i)\n",
        "\n",
        "    print('Finished validation.')\n",
        "    return losses.avg\n",
        "\n",
        "\n",
        "def test(test_loader, model):\n",
        "    model.eval()\n",
        "    use_cuda = True\n",
        "\n",
        "    for i, data in enumerate(tqdm.tqdm(test_loader)):\n",
        "        if use_cuda:\n",
        "            l = data[\"l\"].to('cuda')\n",
        "            hint = data[\"hint\"].to('cuda')\n",
        "            file_name = data[\"file_name\"][0]\n",
        "        else:\n",
        "            l = data[\"l\"]\n",
        "            hint = data[\"hint\"]\n",
        "            file_name = data[\"file_name\"][0]\n",
        "\n",
        "        hint_image = torch.cat((l, hint), dim=1)\n",
        "        output_hint = model(hint_image)\n",
        "\n",
        "        out_hint_np = tensor2im(output_hint)\n",
        "        out_hint_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "        cv2.imwrite(\"outputs/test/\"+file_name, out_hint_bgr)\n",
        "\n",
        "    print('Finished test.')\n"
      ],
      "metadata": {
        "id": "8wAx4cq85c-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "w4Wecsuh5Qbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn\n",
        "\n",
        "## DATALOADER ##\n",
        "# Change to your data root directory\n",
        "root_path = \"./cv_project\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "\n",
        "train_dataset = ColorHintDataset(root_path, 256)\n",
        "train_dataset.set_mode(\"train\")\n",
        "\n",
        "val_dataset = ColorHintDataset(root_path, 256)\n",
        "val_dataset.set_mode(\"val\")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "model = UNet(nin=3, nout=3)\n",
        "# print(model)\n",
        "# PATH = \"model-epoch-8-losses-0.00763.pth\"\n",
        "# model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0)\n",
        "\n",
        "# Move model and loss function to GPU\n",
        "if use_cuda:\n",
        "    criterion = criterion.cuda()\n",
        "    model = model.cuda()\n",
        "# Make folders and set parameters\n",
        "os.makedirs('outputs/GroundTruth', exist_ok=True)\n",
        "os.makedirs('outputs/Hint', exist_ok=True)\n",
        "os.makedirs('outputs/Output', exist_ok=True)\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "save_images = True\n",
        "best_losses = 1e10\n",
        "epochs = 3\n",
        "# Train model\n",
        "for epoch in range(epochs):\n",
        "    # Train for one epoch, then validate\n",
        "    train(train_dataloader, model, criterion, optimizer, epoch)\n",
        "    with torch.no_grad():\n",
        "        losses = validate(val_dataloader, model, criterion, save_images, epoch)\n",
        "    # Save checkpoint and replace old best model if current model is better\n",
        "    if losses < best_losses:\n",
        "        best_losses = losses\n",
        "        torch.save(model.state_dict(), 'checkpoints/model-epoch-{}-losses-{:.5f}.pth'.format(epoch + 1, losses))\n",
        "\n"
      ],
      "metadata": {
        "id": "hBkL0m_l5SY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "UfXdo75n_zzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pylab\n",
        "\n",
        "## DATALOADER ##\n",
        "# Change to your data root directory\n",
        "root_path = \"./test_dataset\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "\n",
        "test_dataset = ColorHintDataset(root_path, 256)\n",
        "test_dataset.set_mode(\"test\")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset)\n",
        "\n",
        "model = UNet(nin=3, nout=3)\n",
        "print(model)\n",
        "PATH = \"./checkpoints/model-epoch-3-losses-0.01682.pth\"\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()\n",
        "\n",
        "os.makedirs('./outputs/test', exist_ok=True)\n",
        "\n",
        "# Move model and loss function to GPU\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "# Make folders and set parameters\n",
        "with torch.no_grad():\n",
        "    test(test_dataloader, model)\n",
        "\n",
        "\n",
        "## calculate and save psnr, ssim ##\n",
        "\n",
        "# change to your Output data directory\n",
        "output_path = \"./outputs/Output\"\n",
        "file_list = os.listdir(output_path)\n",
        "\n",
        "ssim = np.zeros(len(file_list))\n",
        "psnr = np.zeros(len(file_list))\n",
        "\n",
        "for i, img_name in enumerate(file_list):\n",
        "    print(img_name)\n",
        "    name = img_name.replace('.png', '')   # remove '.png'\n",
        "    temp = name.split('_')\n",
        "    ssim[i] += float(temp[1].replace('ssim:', ''))\n",
        "    psnr[i] += float(temp[2].replace('psnr:', ''))\n",
        "\n",
        "ssim_avg = sum(ssim)/len(ssim)\n",
        "psnr_avg = sum(psnr)/len(psnr)\n",
        "\n",
        "print('Average of ssim: {}'.format(ssim_avg))\n",
        "print('Average of psnr: {}'.format(psnr_avg))\n",
        "\n",
        "np.save(os.path.join('./', 'ssim.npy'), ssim)\n",
        "np.save(os.path.join('./', 'psnr.npy'), psnr)\n",
        "\n",
        "# plot and save ssim curve\n",
        "plt.figure()\n",
        "plt.title('ssim')\n",
        "pylab.xlim(0, len(file_list) + 1)\n",
        "pylab.ylim(0, 1.1)\n",
        "plt.plot(range(1, len(file_list) + 1), ssim, label='ssim')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join('./', 'ssim.pdf'))\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# plot and save psnr curve\n",
        "plt.figure()\n",
        "plt.title('pnsr')\n",
        "pylab.xlim(0, len(file_list) + 1)\n",
        "pylab.ylim(0, 100)\n",
        "plt.plot(range(1, len(file_list) + 1), psnr, label='psnr')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join('./', 'psnr.pdf'))\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "9b-lQ9z4_1Fe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}