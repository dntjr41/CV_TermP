{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dntjr41/CV_TermP/blob/main/cv_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdkv0kLjHYu3"
      },
      "source": [
        "# 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPUS5g9Z421E",
        "outputId": "792e9d21-1aa7-4e27-ecda-9f9b4ff482e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V3BKwj8HL3s"
      },
      "source": [
        "# 경로 지정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GPZY2EsHf5X",
        "outputId": "f5ed3250-6200-41e1-e08d-0bacb6f479cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/2022_cv_project\n",
            "/content/drive/My Drive/2022_cv_project\n",
            "total 4442046\n",
            "drwx------ 2 root root       4096 May 23 08:54 checkpoints\n",
            "drwx------ 2 root root       4096 May 23 10:09 cv_project\n",
            "-rw------- 1 root root      28341 May 26 01:35 cv_project.ipynb\n",
            "drwx------ 3 root root       4096 May 23 14:42 cv_project_na\n",
            "-rw------- 1 root root  454219025 May 23 14:36 cv_project_na.zip\n",
            "-rw------- 1 root root 4094316129 May 23 09:54 cv_project.zip\n",
            "drwx------ 3 root root       4096 May 23 08:42 data\n",
            "drwx------ 2 root root       4096 May 23 13:41 .ipynb_checkpoints\n",
            "drwx------ 2 root root       4096 May 23 10:09 __MACOSX\n",
            "drwx------ 6 root root       4096 May 23 08:42 model\n",
            "drwx------ 6 root root       4096 May 23 08:54 outputs\n",
            "-rw------- 1 root root       8128 May 25 14:48 psnr.npy\n",
            "-rw------- 1 root root      16863 May 25 14:48 psnr.pdf\n",
            "drwx------ 2 root root       4096 May 23 14:49 __pycache__\n",
            "drwx------ 3 root root       4096 May 23 14:42 pytorch_ssim\n",
            "-rw------- 1 root root       8128 May 25 14:48 ssim.npy\n",
            "-rw------- 1 root root       6791 May 25 14:48 ssim.pdf\n",
            "-rw------- 1 root root       1623 May 25 14:41 test.py\n",
            "-rw------- 1 root root       4716 May 23 09:47 train.py\n",
            "-rw------- 1 root root       1294 May 24 16:49 utils.py\n"
          ]
        }
      ],
      "source": [
        "%cd drive/My\\ Drive/2022_cv_project\n",
        "!pwd\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-aoW_cLHMxK"
      },
      "source": [
        "# 압축 풀기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCZZIgQ7GGAS",
        "outputId": "1b33c953-1590-48e1-a99e-b0adf1e6f8d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "2000\n",
            "1000\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# # 폴더 복사 하기\n",
        "# import shutil\n",
        "# shutil.copytree('./cv_project', './cv_project_na')\n",
        "\n",
        "# # 파일 크기 확인\n",
        "# filepaths = os.listdir('./cv_project/train')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/val')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/mask')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/hint')\n",
        "# print(len(filepaths))\n",
        "\n",
        "# 압축 풀기\n",
        "file_name = 'cv_project_na'\n",
        "!unzip -qq '{file_name}'\n",
        "\n",
        "# 파일 크기 확인\n",
        "filepaths = os.listdir('./cv_project_na/train')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/val')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/mask')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/hint')\n",
        "print(len(filepaths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## 더 빠른 GPU\n",
        "\n",
        "Colab Pro를 사용하여 가장 빠른 GPU에 우선적으로 액세스하세요. Pro+의 경우 더 빠릅니다. 예를 들어 대부분의 표준 Colab 사용자가 속도가 느린 K80 GPU를 수신할 때 Colab Pro 사용자는 T4 또는 P100 GPU를 이용할 수 있습니다. 언제든지 다음 셀을 실행하여 할당된 GPU를 확인할 수 있습니다.\n",
        "\n",
        "아래 코드 셀의 실행 결과가 ‘Not connected to a GPU’인 경우 메뉴의 런타임 &gt; 런타임 유형 변경에서 런타임을 변경하여 GPU 가속기를 사용 설정한 다음 코드 셀을 다시 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "a7487cc5-b9ad-4ba8-bd7b-c04567ea2328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 26 01:36:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## 추가 메모리\n",
        "\n",
        "<p>Colab Pro를 구독하면 고용량 메모리 VM에 액세스할 수 있습니다&#40;사용 가능한 경우&#41;. Pro+에는 더 많은 메모리가 제공됩니다. 고용량 메모리 런타임을 사용하도록 노트북 환경설정을 지정하려면 런타임 &gt; '런타임 유형 변경' 메뉴를 선택한 다음 런타임 구성 드롭다운에서 고용량 RAM을 선택하세요.</p>\n",
        "<p>언제든지 다음 코드 셀을 실행하여 사용 가능한 메모리 용량을 확인할 수 있습니다.</p>\n",
        "아래 코드 셀의 실행 결과가 ‘Not using a high-RAM runtime’인 경우 메뉴의 런타임 &gt; 런타임 유형 변경에서 고용량 RAM 런타임을 사용 설정하고 런타임 구성 드롭다운에서 고용량 RAM을 선택한 다음 코드 셀을 다시 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1G82GuO-tez",
        "outputId": "fc09c14f-0cc3-4431-cfa0-0ceba31a6d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCGTvywUb96y"
      },
      "source": [
        "# Install pytorch-ssim, mssim\n",
        "<p> pip install pytorch_msssim </p>\n",
        "<p> pip install pytorch_ssim </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Jqh8akdWbq5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c94be84-f366-4e4c-862f-c24f466995a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_msssim\n",
            "  Downloading pytorch_msssim-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch_msssim) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch_msssim) (4.2.0)\n",
            "Installing collected packages: pytorch-msssim\n",
            "Successfully installed pytorch-msssim-0.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch_msssim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA_Dji7vKt5W"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SrUL7biKx7i",
        "outputId": "311c64c7-7871-415d-a363-69f27f934abc"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device 0 : Tesla P100-PCIE-16GB\n",
            "validation dataset:  2000\n",
            "Epoch 1/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/10000 [00:03<10:39:24,  3.84s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.1269 (0.1269)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 501/10000 [11:07<3:52:21,  1.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0354 (0.0362)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1001/10000 [22:08<3:10:33,  1.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0281 (0.0318)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 1501/10000 [33:11<3:00:57,  1.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0374 (0.0301)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2001/10000 [44:05<2:48:23,  1.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0237 (0.0287)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 2501/10000 [55:00<2:39:14,  1.27s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0210 (0.0275)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3001/10000 [1:05:59<2:41:43,  1.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0240 (0.0263)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 3501/10000 [1:16:59<2:20:26,  1.30s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0197 (0.0253)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4001/10000 [1:27:48<2:19:09,  1.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0152 (0.0243)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 4501/10000 [1:38:40<1:50:32,  1.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0256 (0.0233)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5001/10000 [1:49:37<1:52:33,  1.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0099 (0.0225)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 5501/10000 [2:00:36<1:29:11,  1.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0088 (0.0217)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6001/10000 [2:11:25<1:28:24,  1.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0122 (0.0210)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 6501/10000 [2:22:27<1:12:30,  1.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0113 (0.0204)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7001/10000 [2:33:12<1:01:04,  1.22s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0130 (0.0198)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 7501/10000 [2:44:01<1:01:28,  1.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0093 (0.0193)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8001/10000 [2:54:47<37:58,  1.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0101 (0.0188)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 8501/10000 [3:05:30<29:50,  1.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0083 (0.0184)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9001/10000 [3:16:19<20:03,  1.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0097 (0.0180)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 9501/10000 [3:27:05<09:14,  1.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0093 (0.0176)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [3:37:55<00:00,  1.31s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " train Loss: 0.017 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [09:45<00:00,  1.17s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " valid Loss: 0.014 \n",
            "==> best model saved - 0 / 0.014\n",
            "Epoch 2/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/10000 [00:00<2:46:29,  1.00it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0170 (0.0170)\t\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 501/10000 [06:52<2:10:26,  1.21it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t Loss 0.0089 (0.0105)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1001/10000 [13:44<2:03:35,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Loss 0.0140 (0.0103)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 1336/10000 [18:20<1:59:03,  1.21it/s]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from data.dataset import ColorHintDataset\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import cv2\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from data.dataset import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "from model.att_unet.att_unet import Unet\n",
        "import matplotlib.image as img\n",
        "import copy, time\n",
        "from model.sm.model import ResAttdU_Net\n",
        "from utils import AverageMeter, SSIM, psnr, save_img\n",
        "from torchsummary import summary\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project\"\n",
        "\n",
        "    check_path = './checkpoints/'\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    # make the directory\n",
        "    os.makedirs('./checkpoints/', exist_ok=True)\n",
        "    os.makedirs('./outputs/', exist_ok=True)\n",
        "    os.makedirs('./outputs/test', exist_ok=True)\n",
        "    os.makedirs('./outputs/GroundTruth', exist_ok=True)\n",
        "    os.makedirs('./outputs/Hint', exist_ok=True)\n",
        "    os.makedirs('./outputs/Output', exist_ok=True)\n",
        "    os.makedirs('./checkpoints', exist_ok=True)\n",
        "\n",
        "    # Load the data\n",
        "    train_dataset = ColorHintDataset(root_path, 256, \"train\")\n",
        "    val_dataset = ColorHintDataset(root_path, 256, \"val\")\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(train_dataset, batch_size=4, num_workers = 2, shuffle=True)\n",
        "    dataloaders['valid'] = torch.utils.data.DataLoader(val_dataset, batch_size=4, num_workers = 2, shuffle=False)\n",
        "\n",
        "\n",
        "    print('train dataset: ', len(train_dataset))\n",
        "    print('validation dataset: ', len(val_dataset))\n",
        "\n",
        "\n",
        "    # Select the model\n",
        "    models = {'ResUnet': ResUnet(3), 'ResUnetPlusPlus': ResUnetPlusPlus(3), 'UNet': UNet(), 'ResAttdUnet' : ResAttdU_Net()}\n",
        "    model = Unet().to(device)\n",
        "\n",
        "    # load the model\n",
        "    # model.load_state_dict(torch.load('./checkpoints/model-epoch-1-losses-0.00966.pth'))\n",
        "\n",
        "    criterion = torch.nn.L1Loss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    # summary(model, (3, 256, 256))\n",
        "\n",
        "    lmbda = lambda epoch : 0.95\n",
        "    exp_lr_scehduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
        "    epochs = 30\n",
        "\n",
        "    # initialize the\n",
        "    since = time.time()\n",
        "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 999\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            losses = AverageMeter()\n",
        "            psnr_total = 0\n",
        "            ssim_total = 0\n",
        "            count = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for i, data in enumerate(tqdm.tqdm(dataloaders[phase])):\n",
        "                if use_cuda:\n",
        "                    l = data[\"l\"].to(device)\n",
        "                    ab = data[\"ab\"].to(device)\n",
        "                    hint = data[\"hint\"].to(device)\n",
        "                else:\n",
        "                    l = data[\"l\"]\n",
        "                    ab = data[\"ab\"]\n",
        "                    hint = data[\"hint\"]\n",
        "\n",
        "                gt_image = torch.cat((l, ab), dim=1)\n",
        "                hint_image = torch.cat((l, hint), dim=1)\n",
        "                hint_image = hint_image.float().to(device)\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(hint_image)\n",
        "                    loss = criterion(outputs, ab)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        # zero the parameter gradients\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                losses.update(loss.item(), hint_image.size(0))\n",
        "\n",
        "\n",
        "                if phase == 'train':\n",
        "                  if i % 500 == 0:\n",
        "                    print('\\t Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(loss=losses))\n",
        "                \n",
        "                else:\n",
        "                  outputs = torch.cat((l, outputs), dim = 1)\n",
        "                  out_hint_np = tensor2im(outputs)\n",
        "                  out_hint_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "                  hint_np = tensor2im(hint_image)\n",
        "                  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "                  gt_np = tensor2im(gt_image)\n",
        "                  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "                  psnr, ssim = save_img(gt_bgr, hint_bgr, out_hint_bgr, i)\n",
        "                  psnr_total += psnr\n",
        "                  ssim_total += ssim\n",
        "\n",
        "            if phase == 'train':\n",
        "                exp_lr_scehduler.step()\n",
        "                train_loss.append(losses.avg)\n",
        "\n",
        "            else:\n",
        "                print(' {} PSNR AVG : {:.4f} SSIM AVG : {:.4f}'.format(phase, psnr_total/len(datasets[phase]), ssim_total/len(datasets[phase])))\n",
        "                valid_loss.append(losses.avg)\n",
        "\n",
        "            print(' {} Loss: {:.3f} '.format(phase, losses.avg))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and losses.avg < best_loss:\n",
        "                best_idx = epoch\n",
        "                best_loss = losses.avg\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "                # Save model & checkpoint\n",
        "                torch.save(model.state_dict(), './checkpoints/model-epoch-{}-losses-{:.5f}.pth'.format(epoch + 1, best_loss))\n",
        "\n",
        "                print('==> best model saved - %d / %.3f' % (best_idx, best_loss))\n",
        "\n",
        "    # Training Result\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.4f' % (best_idx, best_loss))\n",
        "\n",
        "\n",
        "    # Plot the training procedure\n",
        "    epoch_axis = np.arange(0, epochs)\n",
        "    plt.figure()\n",
        "    plt.title('LOSS')\n",
        "    plt.plot(epoch_axis, train_loss, epoch_axis, valid_loss, 'r-')\n",
        "    plt.legend(['Train', 'Validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbOZp8_DeC3"
      },
      "source": [
        "# Test & Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "6O4g_L2UQEEL",
        "outputId": "c46c2c30-4d86-4a60-c26b-8abfb7fefe75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device 0 : Tesla T4\n",
            "test dataset:  1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6a3d9eb2d245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-6a3d9eb2d245>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# state_dict = torch.load(check_point)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./checkpoints/model-epoch-2-losses-0.01331.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs/test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1498\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Unet:\n\tsize mismatch for one_by_one.weight: copying a param with shape torch.Size([3, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 128, 1, 1]).\n\tsize mismatch for one_by_one.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2])."
          ]
        }
      ],
      "source": [
        "from data.dataset import ColorHintDataset\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import os\n",
        "from data.dataset import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "from model.att_unet.att_unet import Unet\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "  \n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project\"\n",
        "\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    test_dataset = ColorHintDataset(root_path, 256, 'test')\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['test'] = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle=False)\n",
        "    print('test dataset: ', len(test_dataset))\n",
        "\n",
        "\n",
        "    # state_dict = torch.load(check_point)\n",
        "    model = Unet().to(device)\n",
        "    # model.load_state_dict(torch.load('./checkpoints/model-epoch-2-losses-0.01331.pth'))\n",
        "\n",
        "    os.makedirs('outputs/test', exist_ok=True)\n",
        "\n",
        "    model.eval()\n",
        "    for i, data in enumerate(tqdm.tqdm(dataloaders['test'])):\n",
        "        if use_cuda:\n",
        "            l = data[\"l\"].to(device)\n",
        "            hint = data[\"hint\"].to(device)\n",
        "            file_name = data[\"file_name\"][0]\n",
        "\n",
        "        hint_image = torch.cat((l, hint), dim=1)\n",
        "        hint_np = tensor2im(hint_image)\n",
        "        hint_image = hint_image.float().to(device)\n",
        "\n",
        "        output = model(hint_image).squeeze(1)\n",
        "        output = torch.cat((l, output), dim = 1)\n",
        "        out_hint_np = tensor2im(output)\n",
        "\n",
        "\n",
        "        hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "        out_hint_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "\n",
        "        plt.figure(1)\n",
        "        cv2_imshow(hint_bgr)\n",
        "        plt.figure(2)\n",
        "        cv2_imshow(out_hint_bgr)\n",
        "\n",
        "        input()\n",
        "        \n",
        "        # 사진 저장\n",
        "        # fname = str(file_name).replace(\"['\", '')\n",
        "        # fname = fname.replace(\"']\", '')\n",
        "\n",
        "        # cv2.imwrite(\"outputs/test/\"+fname, out_hint_bgr)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr3vTEC-SHGt"
      },
      "source": [
        "# Predict - 얘 안써도 될ㅡ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXkPU0JkSJRj"
      },
      "outputs": [],
      "source": [
        "from data.dataset import ColorHintDataset\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import os\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pylab\n",
        "from test import test\n",
        "\n",
        "def main():\n",
        "    ## calculate and save psnr, ssim ##\n",
        "    with torch.no_grad():\n",
        "      test()\n",
        "    # change to your Output data directory\n",
        "    output_path = \"./outputs/Output\"\n",
        "    file_list = os.listdir(output_path)\n",
        "\n",
        "    ssim = np.zeros(len(file_list))\n",
        "    psnr = np.zeros(len(file_list))\n",
        "\n",
        "    for i, img_name in enumerate(file_list):\n",
        "        # print(img_name)\n",
        "        name = img_name.replace('.png', '')   # remove '.png'\n",
        "        temp = name.split('_')\n",
        "        ssim[i] += float(temp[1].replace('ssim:', ''))\n",
        "        psnr[i] += float(temp[2].replace('psnr:', ''))\n",
        "\n",
        "    ssim_avg = sum(ssim)/len(ssim)\n",
        "    psnr_avg = sum(psnr)/len(psnr)\n",
        "\n",
        "    print('Average of ssim: {}'.format(ssim_avg))\n",
        "    print('Average of psnr: {}'.format(psnr_avg))\n",
        "\n",
        "    np.save(os.path.join('./', 'ssim.npy'), ssim)\n",
        "    np.save(os.path.join('./', 'psnr.npy'), psnr)\n",
        "\n",
        "    # plot and save ssim curve\n",
        "    plt.figure()\n",
        "    plt.title('ssim')\n",
        "    pylab.xlim(0, len(file_list) + 1)\n",
        "    pylab.ylim(0, 1.1)\n",
        "    plt.plot(range(1, len(file_list) + 1), ssim, label='ssim')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join('./', 'ssim.pdf'))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # plot and save psnr curve\n",
        "    plt.figure()\n",
        "    plt.title('pnsr')\n",
        "    pylab.xlim(0, len(file_list) + 1)\n",
        "    pylab.ylim(0, 100)\n",
        "    plt.plot(range(1, len(file_list) + 1), psnr, label='psnr')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join('./', 'psnr.pdf'))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "cv_project.ipynb",
      "provenance": [],
      "mount_file_id": "11QSQX5x8VIYpww6IyIS9no8MbACNXUjk",
      "authorship_tag": "ABX9TyMRjm/5eHNiREj7rPF2YGkT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}