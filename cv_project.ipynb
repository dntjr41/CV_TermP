{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv_project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3tUSEMK1QCid"
      ],
      "machine_shape": "hm",
      "mount_file_id": "11QSQX5x8VIYpww6IyIS9no8MbACNXUjk",
      "authorship_tag": "ABX9TyOy5GvOoF3QlrCmPAxr2YVz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dntjr41/CV_TermP/blob/main/cv_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 드라이브 마운트"
      ],
      "metadata": {
        "id": "Vdkv0kLjHYu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPUS5g9Z421E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843ecf8a-48bc-4ad6-ef14-43b91c3e1cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 경로 지정\n"
      ],
      "metadata": {
        "id": "8V3BKwj8HL3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/2022_cv_project\n",
        "!pwd\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "2GPZY2EsHf5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d50972-a6fd-4fe2-e42c-2e6de1b33ec3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/2022_cv_project\n",
            "/content/drive/My Drive/2022_cv_project\n",
            "total 4442010\n",
            "drwx------ 3 root root       4096 May 24 16:44 checkpoints\n",
            "drwx------ 6 root root       4096 May 23 10:09 cv_project\n",
            "-rw------- 1 root root      32676 May 24 16:54 cv_project.ipynb\n",
            "drwx------ 6 root root       4096 May 23 14:42 cv_project_na\n",
            "-rw------- 1 root root  454219025 May 23 14:36 cv_project_na.zip\n",
            "-rw------- 1 root root 4094316129 May 23 09:54 cv_project.zip\n",
            "drwx------ 3 root root       4096 May 24 10:59 data\n",
            "drwx------ 2 root root       4096 May 23 13:41 .ipynb_checkpoints\n",
            "drwx------ 3 root root       4096 May 23 10:09 __MACOSX\n",
            "drwx------ 6 root root       4096 May 24 15:36 model\n",
            "drwx------ 6 root root       4096 May 24 16:52 outputs\n",
            "drwx------ 2 root root       4096 May 24 16:52 __pycache__\n",
            "drwx------ 3 root root       4096 May 23 14:42 pytorch_ssim\n",
            "-rw------- 1 root root       1637 May 24 11:06 test.py\n",
            "-rw------- 1 root root       4716 May 23 09:47 train.py\n",
            "-rw------- 1 root root       1294 May 24 16:49 utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 압축 풀기"
      ],
      "metadata": {
        "id": "d-aoW_cLHMxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# # 폴더 복사 하기\n",
        "# import shutil\n",
        "# shutil.copytree('./cv_project', './cv_project_na')\n",
        "\n",
        "# # 파일 크기 확인\n",
        "# filepaths = os.listdir('./cv_project/train')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/val')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/mask')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/hint')\n",
        "# print(len(filepaths))\n",
        "\n",
        "# 압축 풀기\n",
        "file_name = 'cv_project_na'\n",
        "!unzip -qq '{file_name}'\n",
        "\n",
        "# 파일 크기 확인\n",
        "filepaths = os.listdir('./cv_project_na/train')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/val')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/mask')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/hint')\n",
        "print(len(filepaths))"
      ],
      "metadata": {
        "id": "ZCZZIgQ7GGAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b33c953-1590-48e1-a99e-b0adf1e6f8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "2000\n",
            "1000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## 더 빠른 GPU\n",
        "\n",
        "Colab Pro를 사용하여 가장 빠른 GPU에 우선적으로 액세스하세요. Pro+의 경우 더 빠릅니다. 예를 들어 대부분의 표준 Colab 사용자가 속도가 느린 K80 GPU를 수신할 때 Colab Pro 사용자는 T4 또는 P100 GPU를 이용할 수 있습니다. 언제든지 다음 셀을 실행하여 할당된 GPU를 확인할 수 있습니다.\n",
        "\n",
        "아래 코드 셀의 실행 결과가 ‘Not connected to a GPU’인 경우 메뉴의 런타임 &gt; 런타임 유형 변경에서 런타임을 변경하여 GPU 가속기를 사용 설정한 다음 코드 셀을 다시 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "23TOba33L4qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e383883a-1f77-4c60-ce75-030ccc6ed845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 24 16:52:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## 추가 메모리\n",
        "\n",
        "<p>Colab Pro를 구독하면 고용량 메모리 VM에 액세스할 수 있습니다&#40;사용 가능한 경우&#41;. Pro+에는 더 많은 메모리가 제공됩니다. 고용량 메모리 런타임을 사용하도록 노트북 환경설정을 지정하려면 런타임 &gt; '런타임 유형 변경' 메뉴를 선택한 다음 런타임 구성 드롭다운에서 고용량 RAM을 선택하세요.</p>\n",
        "<p>언제든지 다음 코드 셀을 실행하여 사용 가능한 메모리 용량을 확인할 수 있습니다.</p>\n",
        "아래 코드 셀의 실행 결과가 ‘Not using a high-RAM runtime’인 경우 메뉴의 런타임 &gt; 런타임 유형 변경에서 고용량 RAM 런타임을 사용 설정하고 런타임 구성 드롭다운에서 고용량 RAM을 선택한 다음 코드 셀을 다시 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V1G82GuO-tez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df16a5f-92b4-45b9-c5b7-37b8d3c34173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install pytorch-ssim, mssim\n",
        "<p> pip install pytorch_msssim </p>\n",
        "<p> pip install pytorch_ssim </p>"
      ],
      "metadata": {
        "id": "uCGTvywUb96y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_msssim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqh8akdWbq5y",
        "outputId": "3f923574-3cb0-4f7b-bce4-040e0aa266f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch_msssim in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch_msssim) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch_msssim) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "cA_Dji7vKt5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from data.dataset import ColorHintDataset\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import cv2\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "from model.att_unet.att_unet import Unet\n",
        "import matplotlib.image as img\n",
        "import copy, time\n",
        "from model.sm.model import ResAttdU_Net\n",
        "from utils import AverageMeter, ssim, save_img\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project\"\n",
        "\n",
        "    check_path = './checkpoints/'\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    # make the directory\n",
        "    os.makedirs('./checkpoints/', exist_ok=True)\n",
        "    os.makedirs('./outputs/', exist_ok=True)\n",
        "    os.makedirs('./outputs/test', exist_ok=True)\n",
        "    os.makedirs('./outputs/GroundTruth', exist_ok=True)\n",
        "    os.makedirs('./outputs/Hint', exist_ok=True)\n",
        "    os.makedirs('./outputs/Output', exist_ok=True)\n",
        "    os.makedirs('./checkpoints', exist_ok=True)\n",
        "\n",
        "    # Load the data\n",
        "    train_dataset = ColorHintDataset(root_path, 256, \"train\")\n",
        "    val_dataset = ColorHintDataset(root_path, 256, \"val\")\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(train_dataset, batch_size=4, num_workers=2, shuffle=True)\n",
        "    dataloaders['valid'] = torch.utils.data.DataLoader(val_dataset, batch_size=4, num_workers=2, shuffle=False)\n",
        "\n",
        "\n",
        "    print('train dataset: ', len(train_dataset))\n",
        "    print('validation dataset: ', len(val_dataset))\n",
        "\n",
        "\n",
        "    # Select the model\n",
        "    models = {'ResUnet': ResUnet(3), 'ResUnetPlusPlus': ResUnetPlusPlus(3), 'UNet': UNet(), 'ResAttdUnet' : ResAttdU_Net()}\n",
        "    model = Unet().to(device)\n",
        "\n",
        "    # load the model\n",
        "    model.load_state_dict(torch.load('./checkpoints/model-epoch-1-losses-0.02557.pth'))\n",
        "\n",
        "    criterion = torch.nn.L1Loss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    lmbda = lambda epoch : 0.95\n",
        "    exp_lr_scehduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
        "    epochs = 30\n",
        "\n",
        "    # initialize the\n",
        "    since = time.time()\n",
        "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 999\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            losses = AverageMeter()\n",
        "\n",
        "            # Iterate over data.\n",
        "            for i, data in enumerate(tqdm.tqdm(dataloaders[phase])):\n",
        "                if use_cuda:\n",
        "                    l = data[\"l\"].to(device)\n",
        "                    ab = data[\"ab\"].to(device)\n",
        "                    hint = data[\"hint\"].to(device)\n",
        "                else:\n",
        "                    l = data[\"l\"]\n",
        "                    ab = data[\"ab\"]\n",
        "                    hint = data[\"hint\"]\n",
        "\n",
        "                gt_image = torch.cat((l, ab), dim=1)\n",
        "                hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(hint_image)\n",
        "                    loss = criterion(outputs, gt_image)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        # zero the parameter gradients\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                losses.update(loss.item(), hint_image.size(0))\n",
        "\n",
        "                if phase == 'train':\n",
        "                  if i % 1000 == 0:\n",
        "                    print('\\t Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(loss=losses))\n",
        "                \n",
        "                else:\n",
        "                  out_hint_np = tensor2im(outputs)\n",
        "                  out_hint_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "                  hint_np = tensor2im(hint_image)\n",
        "                  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "                  gt_np = tensor2im(gt_image)\n",
        "                  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "                  save_img(gt_bgr, hint_bgr, out_hint_bgr, i)\n",
        "\n",
        "            if phase == 'train':\n",
        "                exp_lr_scehduler.step()\n",
        "                train_loss.append(losses.avg)\n",
        "\n",
        "            else:\n",
        "                valid_loss.append(losses.avg)\n",
        "\n",
        "            print(' {} Loss: {:.3f} '.format(phase, losses.avg))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and losses.avg < best_loss:\n",
        "                best_idx = epoch\n",
        "                best_loss = losses.avg\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "                # Save model & checkpoint\n",
        "                torch.save(model.state_dict(), './checkpoints/model-epoch-{}-losses-{:.5f}.pth'.format(epoch + 1, best_loss))\n",
        "\n",
        "                print('==> best model saved - %d / %.3f' % (best_idx, best_loss))\n",
        "\n",
        "    # Training Result\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.4f' % (best_idx, best_loss))\n",
        "\n",
        "\n",
        "    # Plot the training procedure\n",
        "    epoch_axis = np.arange(0, epochs)\n",
        "    plt.figure()\n",
        "    plt.title('LOSS')\n",
        "    plt.plot(epoch_axis, train_loss, epoch_axis, valid_loss, 'r-')\n",
        "    plt.legend(['Train', 'Validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "_SrUL7biKx7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59a4741-2a29-4c6b-95da-da5538008cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [-1, 128, 256, 256]           3,584\n",
            "       BatchNorm2d-2        [-1, 128, 256, 256]             256\n",
            "              ReLU-3        [-1, 128, 256, 256]               0\n",
            "            Conv2d-4        [-1, 128, 256, 256]         147,584\n",
            "       BatchNorm2d-5        [-1, 128, 256, 256]             256\n",
            "              ReLU-6        [-1, 128, 256, 256]               0\n",
            "            Conv2d-7        [-1, 128, 256, 256]           3,584\n",
            "       BatchNorm2d-8        [-1, 128, 256, 256]             256\n",
            "       double_conv-9        [-1, 128, 256, 256]               0\n",
            "        MaxPool2d-10        [-1, 128, 128, 128]               0\n",
            "           Conv2d-11        [-1, 256, 128, 128]         295,168\n",
            "      BatchNorm2d-12        [-1, 256, 128, 128]             512\n",
            "             ReLU-13        [-1, 256, 128, 128]               0\n",
            "           Conv2d-14        [-1, 256, 128, 128]         590,080\n",
            "      BatchNorm2d-15        [-1, 256, 128, 128]             512\n",
            "             ReLU-16        [-1, 256, 128, 128]               0\n",
            "           Conv2d-17        [-1, 256, 128, 128]         295,168\n",
            "      BatchNorm2d-18        [-1, 256, 128, 128]             512\n",
            "      double_conv-19        [-1, 256, 128, 128]               0\n",
            "        MaxPool2d-20          [-1, 256, 64, 64]               0\n",
            "           Conv2d-21          [-1, 512, 64, 64]       1,180,160\n",
            "      BatchNorm2d-22          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-23          [-1, 512, 64, 64]               0\n",
            "           Conv2d-24          [-1, 512, 64, 64]       2,359,808\n",
            "      BatchNorm2d-25          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-26          [-1, 512, 64, 64]               0\n",
            "           Conv2d-27          [-1, 512, 64, 64]       1,180,160\n",
            "      BatchNorm2d-28          [-1, 512, 64, 64]           1,024\n",
            "      double_conv-29          [-1, 512, 64, 64]               0\n",
            "        MaxPool2d-30          [-1, 512, 32, 32]               0\n",
            "           Conv2d-31         [-1, 1024, 32, 32]       4,719,616\n",
            "      BatchNorm2d-32         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-33         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-34         [-1, 1024, 32, 32]       9,438,208\n",
            "      BatchNorm2d-35         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-36         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-37         [-1, 1024, 32, 32]       4,719,616\n",
            "      BatchNorm2d-38         [-1, 1024, 32, 32]           2,048\n",
            "      double_conv-39         [-1, 1024, 32, 32]               0\n",
            "        MaxPool2d-40         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-41         [-1, 2048, 16, 16]      18,876,416\n",
            "      BatchNorm2d-42         [-1, 2048, 16, 16]           4,096\n",
            "             ReLU-43         [-1, 2048, 16, 16]               0\n",
            "           Conv2d-44         [-1, 2048, 16, 16]      37,750,784\n",
            "      BatchNorm2d-45         [-1, 2048, 16, 16]           4,096\n",
            "             ReLU-46         [-1, 2048, 16, 16]               0\n",
            "           Conv2d-47         [-1, 2048, 16, 16]      18,876,416\n",
            "      BatchNorm2d-48         [-1, 2048, 16, 16]           4,096\n",
            "      double_conv-49         [-1, 2048, 16, 16]               0\n",
            "      BatchNorm2d-50         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-51         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-52         [-1, 2048, 32, 32]      18,876,416\n",
            "        MaxPool2d-53         [-1, 2048, 16, 16]               0\n",
            "      BatchNorm2d-54         [-1, 2048, 16, 16]           4,096\n",
            "             ReLU-55         [-1, 2048, 16, 16]               0\n",
            "           Conv2d-56         [-1, 2048, 16, 16]      37,750,784\n",
            "      BatchNorm2d-57         [-1, 2048, 16, 16]           4,096\n",
            "             ReLU-58         [-1, 2048, 16, 16]               0\n",
            "           Conv2d-59         [-1, 2048, 16, 16]       4,196,352\n",
            "          Sigmoid-60         [-1, 2048, 16, 16]               0\n",
            "   AttentionBlock-61         [-1, 2048, 16, 16]               0\n",
            "  ConvTranspose2d-62         [-1, 1024, 32, 32]       8,389,632\n",
            "           Conv2d-63         [-1, 1024, 32, 32]      18,875,392\n",
            "      BatchNorm2d-64         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-65         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-66         [-1, 1024, 32, 32]       9,438,208\n",
            "      BatchNorm2d-67         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-68         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-69         [-1, 1024, 32, 32]      18,875,392\n",
            "      BatchNorm2d-70         [-1, 1024, 32, 32]           2,048\n",
            "      double_conv-71         [-1, 1024, 32, 32]               0\n",
            "      BatchNorm2d-72          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-73          [-1, 512, 64, 64]               0\n",
            "           Conv2d-74         [-1, 1024, 64, 64]       4,719,616\n",
            "        MaxPool2d-75         [-1, 1024, 32, 32]               0\n",
            "      BatchNorm2d-76         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-77         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-78         [-1, 1024, 32, 32]       9,438,208\n",
            "      BatchNorm2d-79         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-80         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-81         [-1, 1024, 32, 32]       1,049,600\n",
            "          Sigmoid-82         [-1, 1024, 32, 32]               0\n",
            "   AttentionBlock-83         [-1, 1024, 32, 32]               0\n",
            "  ConvTranspose2d-84          [-1, 512, 64, 64]       2,097,664\n",
            "           Conv2d-85          [-1, 512, 64, 64]       4,719,104\n",
            "      BatchNorm2d-86          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-87          [-1, 512, 64, 64]               0\n",
            "           Conv2d-88          [-1, 512, 64, 64]       2,359,808\n",
            "      BatchNorm2d-89          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-90          [-1, 512, 64, 64]               0\n",
            "           Conv2d-91          [-1, 512, 64, 64]       4,719,104\n",
            "      BatchNorm2d-92          [-1, 512, 64, 64]           1,024\n",
            "      double_conv-93          [-1, 512, 64, 64]               0\n",
            "      BatchNorm2d-94        [-1, 256, 128, 128]             512\n",
            "             ReLU-95        [-1, 256, 128, 128]               0\n",
            "           Conv2d-96        [-1, 512, 128, 128]       1,180,160\n",
            "        MaxPool2d-97          [-1, 512, 64, 64]               0\n",
            "      BatchNorm2d-98          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-99          [-1, 512, 64, 64]               0\n",
            "          Conv2d-100          [-1, 512, 64, 64]       2,359,808\n",
            "     BatchNorm2d-101          [-1, 512, 64, 64]           1,024\n",
            "            ReLU-102          [-1, 512, 64, 64]               0\n",
            "          Conv2d-103          [-1, 512, 64, 64]         262,656\n",
            "         Sigmoid-104          [-1, 512, 64, 64]               0\n",
            "  AttentionBlock-105          [-1, 512, 64, 64]               0\n",
            " ConvTranspose2d-106        [-1, 256, 128, 128]         524,544\n",
            "          Conv2d-107        [-1, 256, 128, 128]       1,179,904\n",
            "     BatchNorm2d-108        [-1, 256, 128, 128]             512\n",
            "            ReLU-109        [-1, 256, 128, 128]               0\n",
            "          Conv2d-110        [-1, 256, 128, 128]         590,080\n",
            "     BatchNorm2d-111        [-1, 256, 128, 128]             512\n",
            "            ReLU-112        [-1, 256, 128, 128]               0\n",
            "          Conv2d-113        [-1, 256, 128, 128]       1,179,904\n",
            "     BatchNorm2d-114        [-1, 256, 128, 128]             512\n",
            "     double_conv-115        [-1, 256, 128, 128]               0\n",
            " ConvTranspose2d-116        [-1, 128, 256, 256]         131,200\n",
            "          Conv2d-117        [-1, 128, 256, 256]         295,040\n",
            "     BatchNorm2d-118        [-1, 128, 256, 256]             256\n",
            "            ReLU-119        [-1, 128, 256, 256]               0\n",
            "          Conv2d-120        [-1, 128, 256, 256]         147,584\n",
            "     BatchNorm2d-121        [-1, 128, 256, 256]             256\n",
            "            ReLU-122        [-1, 128, 256, 256]               0\n",
            "          Conv2d-123        [-1, 128, 256, 256]         295,040\n",
            "     BatchNorm2d-124        [-1, 128, 256, 256]             256\n",
            "     double_conv-125        [-1, 128, 256, 256]               0\n",
            "          Conv2d-126          [-1, 3, 256, 256]             387\n",
            "         Sigmoid-127          [-1, 3, 256, 256]               0\n",
            "================================================================\n",
            "Total params: 254,141,187\n",
            "Trainable params: 254,141,187\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 2825.00\n",
            "Params size (MB): 969.47\n",
            "Estimated Total Size (MB): 3795.22\n",
            "----------------------------------------------------------------\n",
            "device 0 : Tesla P100-PCIE-16GB\n",
            "train dataset:  40000\n",
            "validation dataset:  2000\n",
            "Epoch 1/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/10000 [00:01<3:08:44,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Loss 0.0300 (0.0300)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 210/10000 [02:51<2:13:28,  1.22it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "3tUSEMK1QCid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data.dataset import ColorHintDataset\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import os\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "  \n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project\"\n",
        "    check_point = './checkpoints/best_model.pt'\n",
        "\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    test_dataset = ColorHintDataset(root_path, 256, \"test\")\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['test'] = torch.utils.data.DataLoader(test_dataset, shuffle=False)\n",
        "    print('test dataset: ', len(test_dataset))\n",
        "\n",
        "\n",
        "    # state_dict = torch.load(check_point)\n",
        "    model = ResUnet(3).to(device)\n",
        "\n",
        "    model.load_state_dict(torch.load(check_point))\n",
        "\n",
        "    os.makedirs('outputs/test', exist_ok=True)\n",
        "\n",
        "    model.eval()\n",
        "    for i, data in enumerate(tqdm.tqdm(dataloaders['test'])):\n",
        "        if use_cuda:\n",
        "            l = data[\"l\"].to(device)\n",
        "            hint = data[\"hint\"].to(device)\n",
        "            mask = data[\"mask\"].to(device)\n",
        "        else:\n",
        "            l = data[\"l\"]\n",
        "            hint = data[\"hint\"]\n",
        "            mask = data[\"mask\"]\n",
        "\n",
        "        filename = data[\"file_name\"]\n",
        "\n",
        "        hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "        output_hint = model(hint_image)\n",
        "        out_hint_np = tensor2im(output_hint)\n",
        "        output_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        fname = str(filename).replace(\"['\", '')\n",
        "        fname = fname.replace(\"']\", '')\n",
        "\n",
        "        cv2.imwrite('./outputs/test/' + str(fname), output_bgr)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "6O4g_L2UQEEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb71509-2e7b-461c-b558-13dc833dced8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device 0 : Tesla P100-PCIE-16GB\n",
            "test dataset:  1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:38<00:00, 26.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "Qr3vTEC-SHGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data.dataset import ColorHintDataset\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import os\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pylab\n",
        "from test import test\n",
        "\n",
        "def main():\n",
        "    ## calculate and save psnr, ssim ##\n",
        "    with torch.no_grad():\n",
        "      test()\n",
        "    # change to your Output data directory\n",
        "    output_path = \"./outputs/Output\"\n",
        "    file_list = os.listdir(output_path)\n",
        "\n",
        "    ssim = np.zeros(len(file_list))\n",
        "    psnr = np.zeros(len(file_list))\n",
        "\n",
        "    for i, img_name in enumerate(file_list):\n",
        "        # print(img_name)\n",
        "        name = img_name.replace('.png', '')   # remove '.png'\n",
        "        temp = name.split('_')\n",
        "        ssim[i] += float(temp[1].replace('ssim:', ''))\n",
        "        psnr[i] += float(temp[2].replace('psnr:', ''))\n",
        "\n",
        "    ssim_avg = sum(ssim)/len(ssim)\n",
        "    psnr_avg = sum(psnr)/len(psnr)\n",
        "\n",
        "    print('Average of ssim: {}'.format(ssim_avg))\n",
        "    print('Average of psnr: {}'.format(psnr_avg))\n",
        "\n",
        "    np.save(os.path.join('./', 'ssim.npy'), ssim)\n",
        "    np.save(os.path.join('./', 'psnr.npy'), psnr)\n",
        "\n",
        "    # plot and save ssim curve\n",
        "    plt.figure()\n",
        "    plt.title('ssim')\n",
        "    pylab.xlim(0, len(file_list) + 1)\n",
        "    pylab.ylim(0, 1.1)\n",
        "    plt.plot(range(1, len(file_list) + 1), ssim, label='ssim')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join('./', 'ssim.pdf'))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # plot and save psnr curve\n",
        "    plt.figure()\n",
        "    plt.title('pnsr')\n",
        "    pylab.xlim(0, len(file_list) + 1)\n",
        "    pylab.ylim(0, 100)\n",
        "    plt.plot(range(1, len(file_list) + 1), psnr, label='psnr')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join('./', 'psnr.pdf'))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "HXkPU0JkSJRj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}