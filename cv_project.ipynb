{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv_project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "d-aoW_cLHMxK",
        "3tUSEMK1QCid"
      ],
      "machine_shape": "hm",
      "mount_file_id": "11QSQX5x8VIYpww6IyIS9no8MbACNXUjk",
      "authorship_tag": "ABX9TyOhOKvqO4WRSpk851ia9P3C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dntjr41/CV_TermP/blob/main/cv_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 드라이브 마운트"
      ],
      "metadata": {
        "id": "Vdkv0kLjHYu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPUS5g9Z421E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b704d83-aa51-45ef-ee94-7981c47c1622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 경로 지정\n"
      ],
      "metadata": {
        "id": "8V3BKwj8HL3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/2022_cv_project\n",
        "!pwd\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "2GPZY2EsHf5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db878a20-37a4-4c87-cdf1-78918374e672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/2022_cv_project\n",
            "/content/drive/My Drive/2022_cv_project\n",
            "total 4442006\n",
            "drwx------ 3 root root       4096 May 23 16:53 checkpoints\n",
            "drwx------ 6 root root       4096 May 23 10:09 cv_project\n",
            "-rw------- 1 root root      28417 May 23 16:55 cv_project.ipynb\n",
            "drwx------ 6 root root       4096 May 23  2022 cv_project_na\n",
            "-rw------- 1 root root  454219025 May 23 14:36 cv_project_na.zip\n",
            "-rw------- 1 root root 4094316129 May 23 09:54 cv_project.zip\n",
            "drwx------ 3 root root       4096 May 23 14:11 data\n",
            "drwx------ 2 root root       4096 May 23 13:41 .ipynb_checkpoints\n",
            "drwx------ 3 root root       4096 May 23 12:52 __MACOSX\n",
            "drwx------ 5 root root       4096 May 23 14:32 model\n",
            "drwx------ 2 root root       4096 May 23 15:01 outputs\n",
            "drwx------ 2 root root       4096 May 23 14:58 __pycache__\n",
            "drwx------ 3 root root       4096 May 23 14:42 pytorch_ssim\n",
            "-rw------- 1 root root       1637 May 23 15:09 test.py\n",
            "-rw------- 1 root root       4716 May 23 09:47 train.py\n",
            "-rw------- 1 root root       1294 May 23 16:54 utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 압축 풀기"
      ],
      "metadata": {
        "id": "d-aoW_cLHMxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# # 폴더 복사 하기\n",
        "# import shutil\n",
        "# shutil.copytree('./cv_project', './cv_project_na')\n",
        "\n",
        "# # 파일 크기 확인\n",
        "# filepaths = os.listdir('./cv_project/train')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/val')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/mask')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/hint')\n",
        "# print(len(filepaths))\n",
        "\n",
        "# 압축 풀기\n",
        "file_name = 'cv_project_na'\n",
        "!unzip -qq '{file_name}'\n",
        "\n",
        "# 파일 크기 확인\n",
        "filepaths = os.listdir('./cv_project_na/train')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/val')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/mask')\n",
        "print(len(filepaths))\n",
        "filepaths = os.listdir('./cv_project_na/hint')\n",
        "print(len(filepaths))"
      ],
      "metadata": {
        "id": "ZCZZIgQ7GGAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b33c953-1590-48e1-a99e-b0adf1e6f8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "2000\n",
            "1000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## 더 빠른 GPU\n",
        "\n",
        "Colab Pro를 사용하여 가장 빠른 GPU에 우선적으로 액세스하세요. Pro+의 경우 더 빠릅니다. 예를 들어 대부분의 표준 Colab 사용자가 속도가 느린 K80 GPU를 수신할 때 Colab Pro 사용자는 T4 또는 P100 GPU를 이용할 수 있습니다. 언제든지 다음 셀을 실행하여 할당된 GPU를 확인할 수 있습니다.\n",
        "\n",
        "아래 코드 셀의 실행 결과가 ‘Not connected to a GPU’인 경우 메뉴의 런타임 &gt; 런타임 유형 변경에서 런타임을 변경하여 GPU 가속기를 사용 설정한 다음 코드 셀을 다시 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d43a18e-9a8a-4c11-bb41-1fd60e508156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Mon May 23 13:34:38 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    33W / 250W |   2467MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## 추가 메모리\n",
        "\n",
        "<p>Colab Pro를 구독하면 고용량 메모리 VM에 액세스할 수 있습니다&#40;사용 가능한 경우&#41;. Pro+에는 더 많은 메모리가 제공됩니다. 고용량 메모리 런타임을 사용하도록 노트북 환경설정을 지정하려면 런타임 &gt; '런타임 유형 변경' 메뉴를 선택한 다음 런타임 구성 드롭다운에서 고용량 RAM을 선택하세요.</p>\n",
        "<p>언제든지 다음 코드 셀을 실행하여 사용 가능한 메모리 용량을 확인할 수 있습니다.</p>\n",
        "아래 코드 셀의 실행 결과가 ‘Not using a high-RAM runtime’인 경우 메뉴의 런타임 &gt; 런타임 유형 변경에서 고용량 RAM 런타임을 사용 설정하고 런타임 구성 드롭다운에서 고용량 RAM을 선택한 다음 코드 셀을 다시 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54665a5-a1ac-4891-810d-c5c8b334b828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install pytorch-ssim, mssim"
      ],
      "metadata": {
        "id": "uCGTvywUb96y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-ssim\n",
        "pip install pytorch-mssim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqh8akdWbq5y",
        "outputId": "a98dc324-16b7-432f-ba06-c0ca765ffaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ssim\n",
            "  Downloading pytorch_ssim-0.1.tar.gz (1.4 kB)\n",
            "Building wheels for collected packages: pytorch-ssim\n",
            "  Building wheel for pytorch-ssim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-ssim: filename=pytorch_ssim-0.1-py3-none-any.whl size=2026 sha256=a31215c9ae5e26913b8fe29d050000934098211ebf3fd30546d123b7a97ddd9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/20/09/ebf5e58bdf2560c760074cd140b7f7b0c882e216feabf1ae30\n",
            "Successfully built pytorch-ssim\n",
            "Installing collected packages: pytorch-ssim\n",
            "Successfully installed pytorch-ssim-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "cA_Dji7vKt5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from data.dataset import ColorHintDataset\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import cv2\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "import matplotlib.image as img\n",
        "import copy, time\n",
        "from model.sm.model import ResAttdU_Net\n",
        "from utils import AverageMeter, ssim, save_img\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project\"\n",
        "\n",
        "    check_path = './checkpoints/'\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    # make the directory\n",
        "    os.makedirs('./checkpoints/', exist_ok=True)\n",
        "    os.makedirs('./outputs/', exist_ok=True)\n",
        "    os.makedirs('./outputs/GroundTruth', exist_ok=True)\n",
        "    os.makedirs('./outputs/Hint', exist_ok=True)\n",
        "    os.makedirs('./outputs/Output', exist_ok=True)\n",
        "    os.makedirs('./checkpoints', exist_ok=True)\n",
        "\n",
        "    # Load the data\n",
        "    train_dataset = ColorHintDataset(root_path, 256, \"train\")\n",
        "    val_dataset = ColorHintDataset(root_path, 256, \"val\")\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "    dataloaders['valid'] = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "\n",
        "    print('train dataset: ', len(train_dataset))\n",
        "    print('validation dataset: ', len(val_dataset))\n",
        "\n",
        "\n",
        "    # Select the model\n",
        "    models = {'ResUnet': ResUnet(3), 'ResUnetPlusPlus': ResUnetPlusPlus(3), 'UNet': UNet(), 'ResAttdUnet' : ResAttdU_Net()}\n",
        "    model = models['ResUnetPlusPlus'].to(device)\n",
        "\n",
        "    criterion = torch.nn.L1Loss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    epochs = 10\n",
        "\n",
        "    # initialize the\n",
        "    since = time.time()\n",
        "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 999\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            losses = AverageMeter()\n",
        "\n",
        "            # Iterate over data.\n",
        "            for i, data in enumerate(tqdm.tqdm(dataloaders[phase])):\n",
        "                if use_cuda:\n",
        "                    l = data[\"l\"].to(device)\n",
        "                    ab = data[\"ab\"].to(device)\n",
        "                    hint = data[\"hint\"].to(device)\n",
        "                else:\n",
        "                    l = data[\"l\"]\n",
        "                    ab = data[\"ab\"]\n",
        "                    hint = data[\"hint\"]\n",
        "\n",
        "                gt_image = torch.cat((l, ab), dim=1)\n",
        "                hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(hint_image)\n",
        "                    loss = criterion(outputs, gt_image)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        # zero the parameter gradients\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                losses.update(loss.item(), hint_image.size(0))\n",
        "\n",
        "                if phase == 'train':\n",
        "                  if i % 1000 == 0:\n",
        "                    print('\\t Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(loss=losses))\n",
        "                \n",
        "                else:\n",
        "                  out_hint_np = tensor2im(outputs)\n",
        "                  out_hint_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "                  hint_np = tensor2im(hint_image)\n",
        "                  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "                  gt_np = tensor2im(gt_image)\n",
        "                  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "                  save_img(gt_bgr, hint_bgr, out_hint_bgr, i)\n",
        "\n",
        "            # if phase == 'train':\n",
        "            #     exp_lr_scheduler.step()\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(losses)\n",
        "\n",
        "            else:\n",
        "                valid_loss.append(losses)\n",
        "\n",
        "            print(' {} Loss: {:.3f} '.format(phase, losses.avg))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and losses.avg < best_loss:\n",
        "                best_idx = epoch\n",
        "                best_loss = losses.avg\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "                # Save model & checkpoint\n",
        "                torch.save(model.state_dict(), './checkpoints/model-epoch-{}-losses-{:.5f}.pth'.format(epoch + 1, best_loss))\n",
        "\n",
        "                print('==> best model saved - %d / %.3f' % (best_idx, best_loss))\n",
        "\n",
        "    # Training Result\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.4f' % (best_idx, best_loss))\n",
        "\n",
        "\n",
        "    # Plot the training procedure\n",
        "    epoch_axis = np.arange(0, epochs)\n",
        "    plt.figure()\n",
        "    plt.title('LOSS')\n",
        "    plt.plot(epoch_axis, train_loss, epoch_axis, valid_loss, 'r-')\n",
        "    plt.legend(['Train', 'Validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "_SrUL7biKx7i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "outputId": "99f75523-6a41-4947-d959-3d22f01155b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device 0 : Tesla P100-PCIE-16GB\n",
            "train dataset:  10000\n",
            "validation dataset:  2000\n",
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2500 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([4, 3, 256, 256])) that is different to the input size (torch.Size([4, 1, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "  0%|          | 1/2500 [00:00<21:42,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Loss 0.1516 (0.1516)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 1001/2500 [05:08<07:34,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Loss 0.0759 (0.1003)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 2001/2500 [10:12<02:32,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Loss 0.0981 (0.0991)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2500/2500 [12:44<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " train Loss: 0.10 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:09<00:00,  7.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " valid Loss: 0.10 \n",
            "==> best model saved - 0 / 0.1\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/2500 [00:00<12:38,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Loss 0.1046 (0.1046)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 1001/2500 [05:04<07:34,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Loss 0.0820 (0.0966)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 2001/2500 [10:09<02:31,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Loss 0.0927 (0.0968)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2500/2500 [12:41<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " train Loss: 0.10 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:10<00:00,  7.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " valid Loss: 0.10 \n",
            "==> best model saved - 1 / 0.1\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/2500 [00:00<12:42,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Loss 0.0975 (0.0975)\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 284/2500 [01:27<11:20,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-30f2ae2ddaf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-30f2ae2ddaf9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "3tUSEMK1QCid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data.dataset import ColorHintDataset\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import os\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "  \n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project\"\n",
        "    check_point = './checkpoints/best_model.pt'\n",
        "\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    test_dataset = ColorHintDataset(root_path, 256, \"test\")\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['test'] = torch.utils.data.DataLoader(test_dataset, shuffle=False)\n",
        "    print('test dataset: ', len(test_dataset))\n",
        "\n",
        "\n",
        "    # state_dict = torch.load(check_point)\n",
        "    model = ResUnet(3).to(device)\n",
        "\n",
        "    model.load_state_dict(torch.load(check_point))\n",
        "\n",
        "    os.makedirs('outputs/test', exist_ok=True)\n",
        "\n",
        "    model.eval()\n",
        "    for i, data in enumerate(tqdm.tqdm(dataloaders['test'])):\n",
        "        if use_cuda:\n",
        "            l = data[\"l\"].to(device)\n",
        "            hint = data[\"hint\"].to(device)\n",
        "            mask = data[\"mask\"].to(device)\n",
        "        else:\n",
        "            l = data[\"l\"]\n",
        "            hint = data[\"hint\"]\n",
        "            mask = data[\"mask\"]\n",
        "\n",
        "        filename = data[\"file_name\"]\n",
        "\n",
        "        hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "        output_hint = model(hint_image)\n",
        "        out_hint_np = tensor2im(output_hint)\n",
        "        output_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        fname = str(filename).replace(\"['\", '')\n",
        "        fname = fname.replace(\"']\", '')\n",
        "\n",
        "        cv2.imwrite('./outputs/test/' + str(fname), output_bgr)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "6O4g_L2UQEEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb71509-2e7b-461c-b558-13dc833dced8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device 0 : Tesla P100-PCIE-16GB\n",
            "test dataset:  1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:38<00:00, 26.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "Qr3vTEC-SHGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data.dataset import ColorHintDataset\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import os\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pylab\n",
        "from test import test\n",
        "\n",
        "def main():\n",
        "    ## calculate and save psnr, ssim ##\n",
        "    with torch.no_grad():\n",
        "      test()\n",
        "    # change to your Output data directory\n",
        "    output_path = \"./outputs/Output\"\n",
        "    file_list = os.listdir(output_path)\n",
        "\n",
        "    ssim = np.zeros(len(file_list))\n",
        "    psnr = np.zeros(len(file_list))\n",
        "\n",
        "    for i, img_name in enumerate(file_list):\n",
        "        # print(img_name)\n",
        "        name = img_name.replace('.png', '')   # remove '.png'\n",
        "        temp = name.split('_')\n",
        "        ssim[i] += float(temp[1].replace('ssim:', ''))\n",
        "        psnr[i] += float(temp[2].replace('psnr:', ''))\n",
        "\n",
        "    ssim_avg = sum(ssim)/len(ssim)\n",
        "    psnr_avg = sum(psnr)/len(psnr)\n",
        "\n",
        "    print('Average of ssim: {}'.format(ssim_avg))\n",
        "    print('Average of psnr: {}'.format(psnr_avg))\n",
        "\n",
        "    np.save(os.path.join('./', 'ssim.npy'), ssim)\n",
        "    np.save(os.path.join('./', 'psnr.npy'), psnr)\n",
        "\n",
        "    # plot and save ssim curve\n",
        "    plt.figure()\n",
        "    plt.title('ssim')\n",
        "    pylab.xlim(0, len(file_list) + 1)\n",
        "    pylab.ylim(0, 1.1)\n",
        "    plt.plot(range(1, len(file_list) + 1), ssim, label='ssim')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join('./', 'ssim.pdf'))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # plot and save psnr curve\n",
        "    plt.figure()\n",
        "    plt.title('pnsr')\n",
        "    pylab.xlim(0, len(file_list) + 1)\n",
        "    pylab.ylim(0, 100)\n",
        "    plt.plot(range(1, len(file_list) + 1), psnr, label='psnr')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join('./', 'psnr.pdf'))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "HXkPU0JkSJRj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}