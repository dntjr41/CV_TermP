{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv_project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Vdkv0kLjHYu3",
        "QMMqmdiYMkvi",
        "65MSuHKqNeBZ"
      ],
      "machine_shape": "hm",
      "toc_visible": true,
      "mount_file_id": "11QSQX5x8VIYpww6IyIS9no8MbACNXUjk",
      "authorship_tag": "ABX9TyPlQEGQPlBaBWli9xav+ayU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dntjr41/CV_TermP/blob/main/cv_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 드라이브 마운트"
      ],
      "metadata": {
        "id": "Vdkv0kLjHYu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPUS5g9Z421E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101f7ca9-715a-4cdd-eee8-3c4c76008aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 경로 지정\n"
      ],
      "metadata": {
        "id": "8V3BKwj8HL3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/2022_cv_project\n",
        "!pwd\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "2GPZY2EsHf5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e285037-ae16-4b01-efc3-621ec78a556f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/2022_cv_project'\n",
            "/content/drive/My Drive/2022_cv_project\n",
            "/content/drive/My Drive/2022_cv_project\n",
            "total 3998415\n",
            "drwx------ 2 root root       4096 May 23 12:43 checkpoints\n",
            "drwx------ 6 root root       4096 May 23 10:09 cv_project\n",
            "-rw------- 1 root root      27701 May 23 12:54 cv_project.ipynb\n",
            "-rw------- 1 root root 4094316129 May 23 09:54 cv_project.zip\n",
            "drwx------ 3 root root       4096 May 23 12:42 data\n",
            "drwx------ 3 root root       4096 May 23 12:52 __MACOSX\n",
            "drwx------ 3 root root       4096 May 23 08:42 model\n",
            "drwx------ 2 root root       4096 May 23 08:54 outputs\n",
            "-rw------- 1 root root       1758 May 23 09:48 test.py\n",
            "-rw------- 1 root root       4716 May 23 09:47 train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 압축 풀기"
      ],
      "metadata": {
        "id": "d-aoW_cLHMxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# # 폴더 복사 하기\n",
        "# import shutil\n",
        "# shutil.copytree('./cv_project', './cv_project_na')\n",
        "\n",
        "# # 파일 크기 확인\n",
        "# filepaths = os.listdir('./cv_project/train')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/val')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/mask')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project/hint')\n",
        "# print(len(filepaths))\n",
        "\n",
        "# 압축 풀기\n",
        "file_name = 'cv_project_na'\n",
        "!unzip -qq '{file_name}'\n",
        "\n",
        "# # 파일 크기 확인\n",
        "# filepaths = os.listdir('./cv_project_na/train')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project_na/val')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project_na/mask')\n",
        "# print(len(filepaths))\n",
        "# filepaths = os.listdir('./cv_project_na/hint')\n",
        "# print(len(filepaths))"
      ],
      "metadata": {
        "id": "ZCZZIgQ7GGAS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## 더 빠른 GPU\n",
        "\n",
        "Colab Pro를 사용하여 가장 빠른 GPU에 우선적으로 액세스하세요. Pro+의 경우 더 빠릅니다. 예를 들어 대부분의 표준 Colab 사용자가 속도가 느린 K80 GPU를 수신할 때 Colab Pro 사용자는 T4 또는 P100 GPU를 이용할 수 있습니다. 언제든지 다음 셀을 실행하여 할당된 GPU를 확인할 수 있습니다.\n",
        "\n",
        "아래 코드 셀의 실행 결과가 ‘Not connected to a GPU’인 경우 메뉴의 런타임 &gt; 런타임 유형 변경에서 런타임을 변경하여 GPU 가속기를 사용 설정한 다음 코드 셀을 다시 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## 추가 메모리\n",
        "\n",
        "<p>Colab Pro를 구독하면 고용량 메모리 VM에 액세스할 수 있습니다&#40;사용 가능한 경우&#41;. Pro+에는 더 많은 메모리가 제공됩니다. 고용량 메모리 런타임을 사용하도록 노트북 환경설정을 지정하려면 런타임 &gt; '런타임 유형 변경' 메뉴를 선택한 다음 런타임 구성 드롭다운에서 고용량 RAM을 선택하세요.</p>\n",
        "<p>언제든지 다음 코드 셀을 실행하여 사용 가능한 메모리 용량을 확인할 수 있습니다.</p>\n",
        "아래 코드 셀의 실행 결과가 ‘Not using a high-RAM runtime’인 경우 메뉴의 런타임 &gt; 런타임 유형 변경에서 고용량 RAM 런타임을 사용 설정하고 런타임 구성 드롭다운에서 고용량 RAM을 선택한 다음 코드 셀을 다시 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "cA_Dji7vKt5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from data.dataset import ColorHintDataset\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import cv2\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "import matplotlib.image as img\n",
        "import copy, time\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project\"\n",
        "    os.makedirs('checkpoints/', exist_ok=True)\n",
        "    check_path = './checkpoints/'\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    # Load the data\n",
        "    train_dataset = ColorHintDataset(root_path, 256, \"train\")\n",
        "    val_dataset = ColorHintDataset(root_path, 256, \"val\")\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "    dataloaders['valid'] = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "\n",
        "    print('train dataset: ', len(train_dataset))\n",
        "    print('validation dataset: ', len(val_dataset))\n",
        "\n",
        "\n",
        "    # Select the model\n",
        "    models = {'ResUnet': ResUnet(3), 'ResUnetPlusPlus': ResUnetPlusPlus(3), 'UNet': UNet()}\n",
        "    model = models['ResUnet'].to(device)\n",
        "\n",
        "    criterion = torch.nn.L1Loss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    epochs = 1\n",
        "\n",
        "    # initialize the\n",
        "    since = time.time()\n",
        "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 999\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for i, data in enumerate(tqdm.tqdm(dataloaders[phase])):\n",
        "                if use_cuda:\n",
        "                    l = data[\"l\"].to(device)\n",
        "                    ab = data[\"ab\"].to(device)\n",
        "                    hint = data[\"hint\"].to(device)\n",
        "                else:\n",
        "                    l = data[\"l\"]\n",
        "                    ab = data[\"ab\"]\n",
        "                    hint = data[\"hint\"]\n",
        "\n",
        "                gt_image = torch.cat((l, ab), dim=1)\n",
        "                hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(hint_image)\n",
        "                    loss = criterion(outputs, gt_image)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.detach().cpu().item()\n",
        "                num_cnt += len(data)\n",
        "\n",
        "            # if phase == 'train':\n",
        "            #     exp_lr_scheduler.step()\n",
        "\n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "            print(' {} Loss: {:.2f} '.format(phase, epoch_loss))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_loss < best_loss:\n",
        "                best_idx = epoch\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                # best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "\n",
        "                # Save model & checkpoint\n",
        "                state = {\n",
        "                    'epoch': epoch,\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict()\n",
        "                }\n",
        "\n",
        "                torch.save(model, check_path + str(best_loss) + '_model.pt')\n",
        "                torch.save(state, check_path + str(best_loss) + '_checkpoint.pt')\n",
        "\n",
        "                print('==> best model saved - %d / %.1f' % (best_idx, best_loss))\n",
        "\n",
        "    # Result\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' % (best_idx, best_loss))\n",
        "\n",
        "    # Save the best model\n",
        "    torch.save(best_model_wts, check_path + 'best_model.pt')\n",
        "\n",
        "    # Plot the training result\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax1.plot(train_loss, 'g-', label='Train_loss')\n",
        "    ax1.plot(valid_loss, 'k-', label='Valid_loss')\n",
        "    plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "    ax1.set_ylabel('loss', color='k')\n",
        "    ax1.tick_params('y', colors='k')\n",
        "    plt.legend(loc='best')\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "_SrUL7biKx7i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "082cdf85-7270-4338-f9eb-97e8b99d3ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device 0 : Tesla P100-PCIE-16GB\n",
            "train dataset:  40000\n",
            "validation dataset:  2000\n",
            "Epoch 1/1\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([4, 3, 256, 256])) that is different to the input size (torch.Size([4, 1, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "100%|██████████| 500/500 [00:50<00:00,  9.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " valid Loss: 0.03 \n",
            "==> best model saved - 0 / 0.0\n",
            "Training complete in 0m 51s\n",
            "Best valid Acc: 0 - 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "3tUSEMK1QCid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data.dataset import ColorHintDataset\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import os\n",
        "from data.transform import tensor2im\n",
        "from model.res_unet.res_unet import ResUnet\n",
        "from model.res_unet.res_unet_plus import ResUnetPlusPlus\n",
        "from model.res_unet.unet import UNet\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  print('device 0 :', torch.cuda.get_device_name(0))\n",
        "  \n",
        "def main():\n",
        "    # Change to your data root directory\n",
        "    root_path = \"./cv_project\"\n",
        "    check_point = './checkpoints/modelname.pt'\n",
        "    # Depend on runtime setting\n",
        "    use_cuda = True\n",
        "\n",
        "    test_dataset = ColorHintDataset(root_path, 256, \"test\")\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['test'] = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "    print('test dataset: ', len(test_dataset))\n",
        "\n",
        "    model = ResUnetPlusPlus(3).cuda()\n",
        "\n",
        "    # model = Unet().cuda()\n",
        "    model.load_state_dict(torch.load(check_point))\n",
        "    os.makedirs('outputs/predict', exist_ok=True)\n",
        "\n",
        "    print('test dataset: ', len(dataloaders['test']))\n",
        "\n",
        "    model.eval()\n",
        "    for i, data in enumerate(tqdm.tqdm(dataloaders['test'])):\n",
        "        if use_cuda:\n",
        "            l = data[\"l\"].to(device)\n",
        "            ab = data[\"ab\"].to(device)\n",
        "            hint = data[\"hint\"].to(device)\n",
        "            mask = data[\"mask\"].to(device)\n",
        "        else:\n",
        "            l = data[\"l\"]\n",
        "            ab = data[\"ab\"]\n",
        "            hint = data[\"hint\"]\n",
        "            mask = data[\"mask\"]\n",
        "\n",
        "        filename = data[\"file_name\"]\n",
        "\n",
        "        hint_image = torch.cat((l, ab, mask), dim=1)\n",
        "\n",
        "        output_hint = model(hint_image)\n",
        "        out_hint_np = tensor2im(output_hint)\n",
        "        output_bgr = cv2.cvtColor(out_hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        fname = str(filename).replace(\"['\", '')\n",
        "        fname = fname.replace(\"']\", '')\n",
        "\n",
        "        cv2.imwrite('./outputs/predict/' + str(fname), output_bgr)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "6O4g_L2UQEEL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}